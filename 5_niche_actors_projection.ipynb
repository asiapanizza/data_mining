{
 "cells": [
  {
   "cell_type": "code",
   "id": "140881fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T02:59:09.236734Z",
     "start_time": "2026-02-14T02:58:25.927406Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "with open(\"actors_projection_graph.json\") as f:\n",
    "    graph_dict = json.load(f)\n",
    "\n",
    "graph = nx.node_link_graph(graph_dict)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "978c01e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T02:59:09.505231Z",
     "start_time": "2026-02-14T02:59:09.338144Z"
    }
   },
   "source": [
    "with open(\"successful_actors.json\") as f:\n",
    "    successful = json.load(f)\n",
    "with open(\"almost_successful_actors.json\") as f:\n",
    "    almost_successful = json.load(f)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "c90a2a7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T01:01:52.825048Z",
     "start_time": "2026-02-14T01:01:52.821724Z"
    }
   },
   "source": [
    "print(successful[\"actor: Tom Hanks\"])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gender': 'male', 'countries': ['Hungary', 'Germany', 'India', 'Mexico', 'United States of America', 'France', 'United Kingdom', 'Singapore', 'Australia', 'Italy', 'Hong Kong', 'Malta'], 'avg_movie_revenue_2020_$': 97984814, 'top_ten': [[1995, 'movie: Toy Story'], [1995, 'movie: Apollo 13'], [1994, 'movie: Forrest Gump'], [1993, 'movie: Philadelphia'], [1993, 'movie: Sleepless in Seattle'], [1996, 'movie: That Thing You Do!'], [1998, 'movie: Saving Private Ryan'], [1989, \"movie: The 'Burbs\"], [1984, 'movie: Splash'], [1986, 'movie: The Money Pit'], [1986, 'movie: Nothing in Common'], [1998, \"movie: You've Got Mail\"], [1988, 'movie: Big'], [1999, 'movie: Return with Honor'], [1999, 'movie: Toy Story 2'], [1990, 'movie: The Bonfire of the Vanities'], [1999, 'movie: The Green Mile'], [1992, 'movie: A League of Their Own'], [1985, 'movie: Volunteers'], [1984, 'movie: Bachelor Party'], [1988, 'movie: Punchline'], [2000, 'movie: Cast Away'], [1989, 'movie: Turner & Hooch'], [1980, \"movie: He Knows You're Alone\"], [1990, 'movie: Joe Versus the Volcano'], [2002, 'movie: Road to Perdition'], [2002, 'movie: Catch Me If You Can'], [1992, 'movie: Radio Flyer'], [1987, 'movie: Dragnet'], [2004, 'movie: The Ladykillers (2004)'], [2004, 'movie: The Terminal'], [1985, 'movie: The Man with One Red Shoe'], [2004, 'movie: The Polar Express'], [1998, 'movie: From the Earth to the Moon'], [2006, 'movie: The Da Vinci Code'], [2006, 'movie: Who Killed the Electric Car?'], [2007, \"movie: Charlie Wilson's War\"], [2008, 'movie: The Great Buck Howard'], [2009, 'movie: Angels & Demons'], [2000, 'movie: Shooting War'], [2010, 'movie: Toy Story 3'], [2007, 'movie: The Pixar Story'], [2011, 'movie: Larry Crowne'], [2011, 'movie: Extremely Loud & Incredibly Close'], [2007, 'movie: The War (2007)'], [2012, 'movie: Cloud Atlas'], [2013, 'movie: Captain Phillips'], [2013, 'movie: Toy Story of Terror!'], [2013, 'movie: Saving Mr. Banks'], [2013, 'movie: Killing Lincoln'], [2011, 'movie: Hawaiian Vacation'], [2004, 'movie: Elvis Has Left the Building'], [2012, 'movie: Partysaurus Rex'], [2014, 'movie: Toy Story That Time Forgot'], [2014, 'movie: And the Oscar Goes To...'], [2017, 'movie: The Circle (2017)'], [2015, 'movie: Bridge of Spies'], [2015, 'movie: Everything Is Copy'], [2013, 'movie: The Sixties'], [2016, 'movie: A Hologram for the King'], [2011, 'movie: The Extraordinary Voyage'], [2016, 'movie: Sully'], [2016, 'movie: Inferno (2016)'], [2011, 'movie: Prohibition'], [2015, 'movie: Ithaca']], 'genre': 'Comedy', 'all_genres': ['Comedy', 'Drama', 'Documentary', 'Family', 'Animation', 'Thriller', 'Romance', 'History', 'Fantasy', 'Crime', 'Action', 'War', 'Adventure', 'Science Fiction', 'Horror', 'Mystery', 'Foreign', 'TV Movie'], 'period': 'new_hollywood', 'bipartite': 1, 'breakthrough': 1988, 'oscar_nomination': True, 'successive_noms': 5, 'post_breakthrough_movies_year': [[1989, 2], [1990, 2], [1992, 2], [1993, 2], [1994, 1], [1995, 2], [1996, 1], [1998, 3], [1999, 2], [2000, 2], [2002, 2], [2004, 4], [2006, 2], [2007, 3], [2008, 1], [2009, 1], [2010, 1], [2011, 4], [2012, 2], [2013, 4], [2014, 2], [2015, 3], [2016, 3], [2017, 1]], 'best_period': '1991-2000'}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "955d7dce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T02:59:12.286323Z",
     "start_time": "2026-02-14T02:59:09.594276Z"
    }
   },
   "source": [
    "nodes = [(n,d) for n, d in graph.nodes(data=True)]\n",
    "edges = [(e1,e2,d) for e1,e2, d in graph.edges(data=True)]\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "732292f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T00:11:09.193567Z",
     "start_time": "2026-02-14T00:11:09.189644Z"
    }
   },
   "source": [
    "print(edges[0])\n",
    "print(nodes[0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('actor: Tom Hanks', 'actor: Kamron Leal', {'weight': 1, 'movies': [['movie: Sully', 2016]], 'earliest_contact': 2016})\n",
      "('actor: Tom Hanks', {'gender': 'male', 'countries': ['Hungary', 'Germany', 'India', 'Mexico', 'United States of America', 'France', 'United Kingdom', 'Singapore', 'Australia', 'Italy', 'Hong Kong', 'Malta'], 'avg_movie_revenue_2020_$': 97984814, 'top_ten': [[1995, 'movie: Toy Story'], [1995, 'movie: Apollo 13'], [1994, 'movie: Forrest Gump'], [1993, 'movie: Philadelphia'], [1993, 'movie: Sleepless in Seattle'], [1996, 'movie: That Thing You Do!'], [1998, 'movie: Saving Private Ryan'], [1989, \"movie: The 'Burbs\"], [1984, 'movie: Splash'], [1986, 'movie: The Money Pit'], [1986, 'movie: Nothing in Common'], [1998, \"movie: You've Got Mail\"], [1988, 'movie: Big'], [1999, 'movie: Return with Honor'], [1999, 'movie: Toy Story 2'], [1990, 'movie: The Bonfire of the Vanities'], [1999, 'movie: The Green Mile'], [1992, 'movie: A League of Their Own'], [1985, 'movie: Volunteers'], [1984, 'movie: Bachelor Party'], [1988, 'movie: Punchline'], [2000, 'movie: Cast Away'], [1989, 'movie: Turner & Hooch'], [1980, \"movie: He Knows You're Alone\"], [1990, 'movie: Joe Versus the Volcano'], [2002, 'movie: Road to Perdition'], [2002, 'movie: Catch Me If You Can'], [1992, 'movie: Radio Flyer'], [1987, 'movie: Dragnet'], [2004, 'movie: The Ladykillers (2004)'], [2004, 'movie: The Terminal'], [1985, 'movie: The Man with One Red Shoe'], [2004, 'movie: The Polar Express'], [1998, 'movie: From the Earth to the Moon'], [2006, 'movie: The Da Vinci Code'], [2006, 'movie: Who Killed the Electric Car?'], [2007, \"movie: Charlie Wilson's War\"], [2008, 'movie: The Great Buck Howard'], [2009, 'movie: Angels & Demons'], [2000, 'movie: Shooting War'], [2010, 'movie: Toy Story 3'], [2007, 'movie: The Pixar Story'], [2011, 'movie: Larry Crowne'], [2011, 'movie: Extremely Loud & Incredibly Close'], [2007, 'movie: The War (2007)'], [2012, 'movie: Cloud Atlas'], [2013, 'movie: Captain Phillips'], [2013, 'movie: Toy Story of Terror!'], [2013, 'movie: Saving Mr. Banks'], [2013, 'movie: Killing Lincoln'], [2011, 'movie: Hawaiian Vacation'], [2004, 'movie: Elvis Has Left the Building'], [2012, 'movie: Partysaurus Rex'], [2014, 'movie: Toy Story That Time Forgot'], [2014, 'movie: And the Oscar Goes To...'], [2017, 'movie: The Circle (2017)'], [2015, 'movie: Bridge of Spies'], [2015, 'movie: Everything Is Copy'], [2013, 'movie: The Sixties'], [2016, 'movie: A Hologram for the King'], [2011, 'movie: The Extraordinary Voyage'], [2016, 'movie: Sully'], [2016, 'movie: Inferno (2016)'], [2011, 'movie: Prohibition'], [2015, 'movie: Ithaca']], 'genre': 'Comedy', 'all_genres': ['Comedy', 'Drama', 'Documentary', 'Family', 'Animation', 'Thriller', 'Romance', 'History', 'Fantasy', 'Crime', 'Action', 'War', 'Adventure', 'Science Fiction', 'Horror', 'Mystery', 'Foreign', 'TV Movie'], 'period': 'new_hollywood', 'bipartite': 1, 'breakthrough': 1988, 'oscar_nomination': True, 'successive_noms': 5, 'post_breakthrough_movies_year': [[1989, 2], [1990, 2], [1992, 2], [1993, 2], [1994, 1], [1995, 2], [1996, 1], [1998, 3], [1999, 2], [2000, 2], [2002, 2], [2004, 4], [2006, 2], [2007, 3], [2008, 1], [2009, 1], [2010, 1], [2011, 4], [2012, 2], [2013, 4], [2014, 2], [2015, 3], [2016, 3], [2017, 1]], 'best_period': '1991-2000', 'contacts_before_breakthrough': [['actor: Allan Arbus', 1985], ['actor: Elizabeth Kemp', 1980], ['actor: Edward Herrmann', 1985], ['actor: Florence Schauffler', 1984], ['actor: Dortha Duckworth', 1985], ['actor: Elizabeth Ashley', 1987], ['actor: Frank Hamilton', 1985], ['actor: Frankie Faison', 1986], ['actor: Irving Metzman', 1985], ['actor: Billy Beck', 1984], ['actor: William Tepper', 1984], ['actor: Tom Toner', 1984], ['actor: Monique Gabrielle', 1984], ['actor: Gary Grossman', 1984], ['actor: Alexandra Paul', 1987], ['actor: Shelley Long', 1986], ['actor: Dody Goodman', 1984], ['actor: Howard Morris', 1984], ['actor: Jim Belushi', 1985], ['actor: Rebecca Perle', 1984], ['actor: Steve James', 1980], ['actor: Anne Gaybis', 1984], ['actor: Damita Jo Freeman', 1985], ['actor: Ernest Harada', 1985], ['actor: Philip Bosco', 1986], ['actor: Dabney Coleman', 1985], ['actor: Tom Noonan', 1985], ['actor: Alexander Godunov', 1986], ['actor: Adrian Zmed', 1984], ['actor: Dan Castellaneta', 1986], ['actor: Carrie Fisher', 1985], ['actor: Art LaFleur', 1985], ['actor: Mark Robman', 1985], [\"actor: Jack O'Halloran\", 1987], ['actor: Sam Sako', 1985], ['actor: Robert Prescott', 1984], ['actor: Xander Berkeley', 1985], ['actor: Christopher Plummer', 1987], ['actor: Nestor Serrano', 1986], ['actor: Gedde Watanabe', 1985], ['actor: Tom Rolfing', 1980], ['actor: Douglass Watson', 1986], ['actor: Rita Wilson', 1985], ['actor: Héctor Elizondo', 1986], ['actor: Eugene Levy', 1984], ['actor: John Candy', 1984], ['actor: James Carroll', 1980], ['actor: Charles Durning', 1985], ['actor: James Rebhorn', 1980], ['actor: Jackie Gleason', 1986], ['actor: Bradford Bancroft', 1984], ['actor: Tom Rayhall', 1985], ['actor: Johnny Yune', 1986], ['actor: Ivy Bethune', 1985], ['actor: Sela Ward', 1986], ['actor: Tim Thomerson', 1985], ['actor: Shannon Tweed', 1987], ['actor: Julius Carry', 1985], ['actor: Patsy Pease', 1980], ['actor: Maureen Stapleton', 1986], ['actor: David Selburg', 1985], ['actor: John Bloom', 1984], ['actor: Richard McGonagle', 1985], ['actor: Dana Barron', 1980], ['actor: Ritch Brinkley', 1985], ['actor: Lisa London', 1987], ['actor: Bobby Di Cicco', 1984], ['actor: Stephen Bradley', 1985], ['actor: Lori Singer', 1985], ['actor: Barbara Stuart', 1984], ['actor: Angela Aames', 1984], ['actor: Fred Lerner', 1984], ['actor: George Plimpton', 1985], ['actor: Lewis Arlt', 1980], ['actor: Joe Mantegna', 1986], ['actor: Dan Resin', 1985], ['actor: Barry Corbin', 1986], ['actor: Jake Steinfeld', 1986], ['actor: Jeff Ware', 1985], ['actor: Michael Dudikoff', 1984], ['actor: Daryl Hannah', 1984], ['actor: David L. Lander', 1985], ['actor: Richard B. Shull', 1984], ['actor: Michael Jeter', 1986], ['actor: Ji-Tu Cumbuka', 1984], ['actor: George Grizzard', 1984], ['actor: Shecky Greene', 1984], ['actor: Yakov Smirnoff', 1986], ['actor: Wendie Jo Sperber', 1984], [\"actor: Caitlin O'Heaney\", 1980], ['actor: David Ogden Stiers', 1985], ['actor: Barry Diamond', 1984], ['actor: Paul Gleason', 1980], ['actor: Dan Aykroyd', 1987], ['actor: Richard Clark', 1985], ['actor: Wendell Pierce', 1986], ['actor: Don Scardino', 1980], ['actor: Tawny Kitaen', 1984], ['actor: Charles Walker', 1985], ['actor: Carmine Caridi', 1986], ['actor: Kathleen Freeman', 1987], ['actor: Noel De Souza', 1985], ['actor: Victoria Carroll', 1985], ['actor: Mike Hagerty', 1986], ['actor: Tracy Reiner', 1986], ['actor: Mia Dillon', 1986], ['actor: Tom Chiu', 1985], ['actor: Deborah Harmon', 1984], ['actor: Billy Lombardo', 1986], ['actor: Lowell Ganz', 1984], ['actor: Tetchie Agbayani', 1986], ['actor: Harry Morgan', 1987], ['actor: Brian Backer', 1986], ['actor: Joseph Leon', 1980], ['actor: Gerrit Graham', 1985], ['actor: Babaloo Mandel', 1984], ['actor: Bess Armstrong', 1986], ['actor: Lucille Dobrin', 1986], ['actor: Dan Ziskie', 1985], ['actor: Brett Baxter Clark', 1984], ['actor: Toni Alessandrini', 1984], ['actor: John van Dreelen', 1986], ['actor: Eva Marie Saint', 1986], ['actor: Conrad Janis', 1986], ['actor: Rosanne Katon', 1984], ['actor: Lisa Raggio', 1985], ['actor: George Martin', 1985], ['actor: Tracy Smith', 1984], ['actor: Michele Starck', 1984], ['actor: Leslie West', 1986], ['actor: Charles Levin', 1985], ['actor: Patricia Gaul', 1985], ['actor: Josh Mostel', 1986]]})\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "f6c0399c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T02:59:14.257138Z",
     "start_time": "2026-02-14T02:59:12.376159Z"
    }
   },
   "source": [
    "# let's create a graph with only the most successful actors to see how they connect to each other\n",
    "\n",
    "niche_graph = nx.DiGraph()\n",
    "for actor,diz in successful.items():\n",
    "    niche_graph.add_node(actor, **diz)\n",
    "\n",
    "for edge in edges:\n",
    "    actor1 = edge[0]\n",
    "    actor2 = edge[1]\n",
    "    if actor1 and actor2 in successful:\n",
    "        if \"contacts_before_breakthrough\" in graph.nodes[actor1]:\n",
    "            for colleague in graph.nodes[actor1][\"contacts_before_breakthrough\"]:\n",
    "                if actor2 == colleague[0]:\n",
    "                    niche_graph.add_edge(actor1, actor2, **{\"year\":colleague[1]})\n",
    "        if \"contacts_before_breakthrough\" in graph.nodes[actor2]:\n",
    "            for colleague in graph.nodes[actor2][\"contacts_before_breakthrough\"]:\n",
    "                if actor1 == colleague[0]:\n",
    "                    niche_graph.add_edge(actor2, actor1, **{\"year\":colleague[1]})\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "2dedaab6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T02:59:33.245125Z",
     "start_time": "2026-02-14T02:59:14.350994Z"
    }
   },
   "source": [
    "# let's create a graph with only non-successful actors to see how they connect to each other\n",
    "\n",
    "almost_niche_graph = nx.DiGraph()\n",
    "for actor,diz in almost_successful.items():\n",
    "    almost_niche_graph.add_node(actor, **diz)\n",
    "\n",
    "for edge in edges:\n",
    "    actor1 = edge[0]\n",
    "    actor2 = edge[1]\n",
    "    if actor1 and actor2 in almost_successful:\n",
    "        if \"contacts_before_breakthrough\" in graph.nodes[actor1]:\n",
    "            for colleague in graph.nodes[actor1][\"contacts_before_breakthrough\"]:\n",
    "                if actor2 == colleague[0]:\n",
    "                    almost_niche_graph.add_edge(actor1, actor2, **{\"year\":colleague[1]})\n",
    "        if \"contacts_before_breakthrough\" in graph.nodes[actor2]:\n",
    "            for colleague in graph.nodes[actor2][\"contacts_before_breakthrough\"]:\n",
    "                if actor1 == colleague[0]:\n",
    "                    almost_niche_graph.add_edge(actor2, actor1, **{\"year\":colleague[1]})\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "4d043bd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T03:02:26.505129Z",
     "start_time": "2026-02-14T03:02:22.552628Z"
    }
   },
   "source": [
    "# let's create a graph with the most successful actors and those who almost made it to see how they connect to each other\n",
    "\n",
    "mixed_graph = nx.DiGraph()\n",
    "for actor,diz in successful.items():\n",
    "    diz[\"status\"] = \"successful\"\n",
    "    mixed_graph.add_node(actor, **diz)\n",
    "for actor,diz in almost_successful.items():\n",
    "    diz[\"status\"] = \"almost_successful\"\n",
    "    mixed_graph.add_node(actor, **diz)\n",
    "\n",
    "for edge in edges:\n",
    "    actor1 = edge[0]\n",
    "    actor2 = edge[1]\n",
    "    if actor1 in almost_successful and actor2 in successful:\n",
    "        if \"contacts_before_breakthrough\" in graph.nodes[actor1]:\n",
    "            for colleague in graph.nodes[actor1][\"contacts_before_breakthrough\"]:\n",
    "                if actor2 == colleague[0]:\n",
    "                    mixed_graph.add_edge(actor1, actor2, **{\"year\":colleague[1]})\n",
    "        if \"contacts_before_breakthrough\" in graph.nodes[actor2]:\n",
    "            for colleague in graph.nodes[actor2][\"contacts_before_breakthrough\"]:\n",
    "                if actor1 == colleague[0]:\n",
    "                    mixed_graph.add_edge(actor2, actor1, **{\"year\":colleague[1]})\n",
    "    if actor1 in successful and actor2 in almost_successful:\n",
    "        if \"contacts_before_breakthrough\" in graph.nodes[actor1]:\n",
    "            for colleague in graph.nodes[actor1][\"contacts_before_breakthrough\"]:\n",
    "                if actor2 == colleague[0]:\n",
    "                    mixed_graph.add_edge(actor1, actor2, **{\"year\":colleague[1]})\n",
    "        if \"contacts_before_breakthrough\" in graph.nodes[actor2]:\n",
    "            for colleague in graph.nodes[actor2][\"contacts_before_breakthrough\"]:\n",
    "                if actor1 == colleague[0]:\n",
    "                    mixed_graph.add_edge(actor2, actor1, **{\"year\": colleague[1]})\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab77926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find mentors, mentees and peers\n",
    "# mentor: someone who has an edge incoming from someone, but not one outgoing to that someone\n",
    "# mentor: someone who has an edge outgoing to someone, but not one incoming from that someone\n",
    "# peers: actors who knew each other before either made it\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "f29b351c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T02:25:13.276755Z",
     "start_time": "2026-02-14T02:25:13.265154Z"
    }
   },
   "source": [
    "niche_all_connections=list(niche_graph.edges())"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "baaa6cdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T02:25:13.417107Z",
     "start_time": "2026-02-14T02:25:13.394694Z"
    }
   },
   "source": [
    "niche_in_out = dict()\n",
    "for tup in niche_all_connections:\n",
    "    start = tup[0]\n",
    "    end = tup[1]\n",
    "    if start not in niche_in_out:\n",
    "        niche_in_out[start] = dict()\n",
    "        niche_in_out[start][\"incoming\"] = list()\n",
    "        niche_in_out[start][\"outgoing\"] = list()\n",
    "        \n",
    "    if end not in niche_in_out:\n",
    "        niche_in_out[end] = dict()\n",
    "        niche_in_out[end][\"incoming\"] = list()\n",
    "        niche_in_out[end][\"outgoing\"] = list()        \n",
    "    niche_in_out[start][\"outgoing\"].append(end)\n",
    "    niche_in_out[end][\"incoming\"].append(start) \n",
    "    \n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "8f2e5bbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T01:02:21.751058Z",
     "start_time": "2026-02-14T01:02:21.739918Z"
    }
   },
   "source": [
    "niche_ordered_by_outgoing = {node: len(connected['outgoing']) for node, connected in niche_in_out.items()}\n",
    "niche_biggest_mentors = sorted(niche_ordered_by_outgoing.items(), key=lambda item: item[1], reverse=True)\n",
    "niche_ordered_by_incoming= {node: len(connected['incoming']) for node, connected in niche_in_out.items()}\n",
    "niche_biggest_mentees = sorted(niche_ordered_by_incoming.items(), key=lambda item: item[1], reverse=True)\n",
    "print(niche_biggest_mentors[:5])\n",
    "print(niche_biggest_mentees[:5])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('actor: Donald Crisp', 358), ('actor: John Wayne', 356), ('actor: Lee Marvin', 278), ('actor: William Demarest', 241), ('actor: J. Carrol Naish', 231)]\n",
      "[('actor: John Wayne', 230), ('actor: Donald Crisp', 195), ('actor: Brian Donlevy', 192), ('actor: Henry Fonda', 183), ('actor: Walter Brennan', 178)]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "5e44ee51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T01:02:22.093905Z",
     "start_time": "2026-02-14T01:02:21.932002Z"
    }
   },
   "source": [
    "almost_niche_all_connections=list(almost_niche_graph.edges())\n",
    "#almost_niche_all_connections = [(a1,a2) for a1, a2 in almost_niche_all_connections]"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "f03cb096",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T01:02:22.932765Z",
     "start_time": "2026-02-14T01:02:22.227937Z"
    }
   },
   "source": [
    "almost_niche_in_out = dict()\n",
    "\n",
    "for tup in almost_niche_all_connections:\n",
    "    start = tup[0]\n",
    "    end = tup[1]\n",
    "    if start not in almost_niche_in_out:\n",
    "        almost_niche_in_out[start] = dict()\n",
    "        almost_niche_in_out[start][\"incoming\"] = list()\n",
    "        almost_niche_in_out[start][\"outgoing\"] = list()       \n",
    "    if end not in almost_niche_in_out:\n",
    "        almost_niche_in_out[end] = dict()\n",
    "        almost_niche_in_out[end][\"incoming\"] = list()\n",
    "        almost_niche_in_out[end][\"outgoing\"] = list()        \n",
    "    almost_niche_in_out[start][\"outgoing\"].append(end)\n",
    "    almost_niche_in_out[end][\"incoming\"].append(start) \n",
    "    \n"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "5b79e532",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T01:02:23.212915Z",
     "start_time": "2026-02-14T01:02:23.118395Z"
    }
   },
   "source": [
    "almost_niche_ordered_by_outgoing = {node: len(connected['outgoing']) for node, connected in almost_niche_in_out.items()}\n",
    "almost_niche_biggest_mentors = sorted(almost_niche_ordered_by_outgoing.items(), key=lambda item: item[1], reverse=True)\n",
    "almost_niche_ordered_by_incoming= {node: len(connected['incoming']) for node, connected in almost_niche_in_out.items()}\n",
    "almost_niche_biggest_mentees = sorted(almost_niche_ordered_by_incoming.items(), key=lambda item: item[1], reverse=True)\n",
    "print(almost_niche_biggest_mentors[:5])\n",
    "print(almost_niche_biggest_mentees[:5])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('actor: Charles Lane', 930), ('actor: Sam Harris', 815), ('actor: Bess Flowers', 740), ('actor: Danny Trejo', 724), ('actor: James Flavin', 719)]\n",
      "[('actor: Bess Flowers', 670), ('actor: Russell Hicks', 443), ('actor: Gino Corrado', 420), ('actor: Charles Lane', 420), ('actor: Selmer Jackson', 417)]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "97a4bb27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T01:02:23.618401Z",
     "start_time": "2026-02-14T01:02:23.526043Z"
    }
   },
   "source": [
    "mixed_all_connections=list(mixed_graph.edges())\n",
    "\n",
    "mixed_in_out = dict()\n",
    "\n",
    "for tup in mixed_all_connections:\n",
    "    start = tup[0]\n",
    "    end = tup[1]\n",
    "    if start not in mixed_in_out:\n",
    "        mixed_in_out[start] = dict()\n",
    "        mixed_in_out[start][\"incoming\"] = list()\n",
    "        mixed_in_out[start][\"outgoing\"] = list()       \n",
    "    if end not in mixed_in_out:\n",
    "        mixed_in_out[end] = dict()\n",
    "        mixed_in_out[end][\"incoming\"] = list()\n",
    "        mixed_in_out[end][\"outgoing\"] = list()        \n",
    "    mixed_in_out[start][\"outgoing\"].append(end)\n",
    "    mixed_in_out[end][\"incoming\"].append(start) \n",
    "    \n"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c26caf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('actor: John Wayne', 411), ('actor: Donald Crisp', 370), ('actor: William Demarest', 332), ('actor: George Sanders', 322), ('actor: Humphrey Bogart', 311)]\n",
      "[('actor: Samuel L. Jackson', 323), ('actor: Christopher Walken', 306), ('actor: John Wayne', 302), ('actor: Robert De Niro', 277), ('actor: Dan Aykroyd', 266)]\n"
     ]
    }
   ],
   "source": [
    "mixed_ordered_by_outgoing = {node: len(connected['outgoing']) for node, connected in mixed_in_out.items()}\n",
    "mixed_biggest_mentors = sorted(mixed_ordered_by_outgoing.items(), key=lambda item: item[1], reverse=True)\n",
    "mixed_ordered_by_incoming= {node: len(connected['incoming']) for node, connected in mixed_in_out.items()}\n",
    "mixed_biggest_mentees = sorted(mixed_ordered_by_incoming.items(), key=lambda item: item[1], reverse=True)\n",
    "print(mixed_biggest_mentors[:5])\n",
    "print(mixed_biggest_mentees[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389bcba4",
   "metadata": {},
   "source": [
    "# ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2398ff96",
   "metadata": {},
   "source": [
    "### CENTRALITIES"
   ]
  },
  {
   "cell_type": "code",
   "id": "1c38c01b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T01:26:40.340342Z",
     "start_time": "2026-02-14T01:26:40.332138Z"
    }
   },
   "source": [
    "import statistics\n",
    "import pandas as pd\n",
    "\n",
    "def compute_centrality_nx(kind, function,df):\n",
    "    niche_betweenness = function(niche_graph)\n",
    "    almost_niche_betweenness = function(almost_niche_graph)\n",
    "    mixed_betweenness = function(mixed_graph)\n",
    "\n",
    "    items_niche_betweenness = niche_betweenness.items()\n",
    "    top_10_niche_betweenness = sorted(items_niche_betweenness, key = lambda x: x[1])[:10]\n",
    "    avg_niche_betweenness = statistics.mean([value for name, value in niche_betweenness.items()])\n",
    "    max_niche_betweenness = max([value for name,value in top_10_niche_betweenness])\n",
    "\n",
    "    items_almost_niche_betweenness = almost_niche_betweenness.items()\n",
    "    top_10_almost_niche_betweenness  = sorted(items_almost_niche_betweenness, key = lambda x: x[1])[:10]\n",
    "    avg_almost_niche_betweenness= statistics.mean([value for name, value in almost_niche_betweenness.items()])\n",
    "    max_almost_niche_betweenness = max([value for name,value in top_10_almost_niche_betweenness])\n",
    "\n",
    "    items_mixed_betweenness= mixed_betweenness.items()\n",
    "    top_10_mixed_betweenness  = sorted(items_mixed_betweenness, key = lambda x: x[1])[:10]\n",
    "    avg_mixed_betweenness = statistics.mean([value for name, value in mixed_betweenness.items()])\n",
    "    max_mixed_betweenness = max([value for name,value in top_10_mixed_betweenness])\n",
    "\n",
    "    df.loc[f\"Average {kind} centrality\"] = [avg_niche_betweenness, avg_almost_niche_betweenness, avg_mixed_betweenness]\n",
    "    df.loc[f\"Maximum {kind} centrality\"] = [max_niche_betweenness, max_almost_niche_betweenness, max_mixed_betweenness]\n",
    "\n",
    "\n",
    "    to_save = dict()\n",
    "    to_save[\"niche_graph\"] = top_10_niche_betweenness\n",
    "    to_save[\"almost_niche_graph\"] = top_10_almost_niche_betweenness\n",
    "    to_save[\"mixed_graph\"] = top_10_mixed_betweenness\n",
    "\n",
    "    with open(f\"analysis_5/{kind}_centralities.json\", \"w\") as f:\n",
    "        json.dump(to_save,f, indent=4)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T03:13:50.837520Z",
     "start_time": "2026-02-14T03:13:50.346068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import networkit as nk\n",
    "#centrality_df = pd.DataFrame(columns=[\"Niche graph\", \"Almost niche graph\", \"Mixed graph\"])\n",
    "centrality_df = pd.read_json(\"analysis_5/centrality.json\")\n",
    "print(centrality_df)\n",
    "niche_nodes_list = list(niche_graph.nodes())\n",
    "almost_niche_nodes_list = list(almost_niche_graph.nodes())\n",
    "mixed_nodes_list = list(mixed_graph.nodes())\n",
    "nk.setNumberOfThreads(7)\n",
    "niche_graph_nk = nk.nxadapter.nx2nk(niche_graph)\n",
    "almost_niche_graph_nk = nk.nxadapter.nx2nk(almost_niche_graph)\n",
    "mixed_graph_nk = nk.nxadapter.nx2nk(mixed_graph)"
   ],
   "id": "d9153c18a91f443",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Niche graph  Almost niche graph  \\\n",
      "Average closeness centrality               0.135567            0.119990   \n",
      "Maximum closeness centrality               0.297890            0.365055   \n",
      "Average pagerank centrality                0.000179            0.000026   \n",
      "Maximum pagerank centrality                0.000054            0.000011   \n",
      "Average betweenness centrality             0.000293            0.000039   \n",
      "Maximum betweenness centrality             0.048626            0.012395   \n",
      "Maximum normalized pagerank centrality     0.302622            0.408903   \n",
      "\n",
      "                                        Mixed graph  \n",
      "Average closeness centrality               0.064286  \n",
      "Maximum closeness centrality               0.186468  \n",
      "Average pagerank centrality                0.000065  \n",
      "Maximum pagerank centrality                0.000025  \n",
      "Average betweenness centrality             0.000052  \n",
      "Maximum betweenness centrality             0.008766  \n",
      "Maximum normalized pagerank centrality     0.388181  \n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "ec4bff04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T01:20:08.744713Z",
     "start_time": "2026-02-14T01:18:09.434472Z"
    }
   },
   "source": [
    "import statistics\n",
    "import pandas as pd\n",
    "import networkit as nk\n",
    "import os\n",
    "\n",
    "\n",
    "top10_betweenness = dict()\n",
    "avg_betweenness = dict()\n",
    "max_betweenness = dict()\n",
    "\n",
    "def compute_betweenness(graph, graph_name, nodes_list):\n",
    "    betweenness = nk.centrality.Betweenness(graph, normalized=True)\n",
    "    betweenness.run()\n",
    "    scores = betweenness.scores()\n",
    "    node_scores = list(enumerate(scores))\n",
    "    #print(scores)\n",
    "    id_sorted_scores = sorted(node_scores, key=lambda x: x[1], reverse=True)\n",
    "    name_sorted_scores = list()\n",
    "    for id, score in id_sorted_scores[:10]:\n",
    "        name = nodes_list[id]\n",
    "        name_sorted_scores.append((name, score))\n",
    "    top_10_betweenness = name_sorted_scores\n",
    "    avg_betweenness_value = statistics.mean(scores)\n",
    "    max_betweenness_value = name_sorted_scores[0][1]\n",
    "    top10_betweenness[graph_name] = top_10_betweenness\n",
    "    avg_betweenness[graph_name] = avg_betweenness_value\n",
    "    max_betweenness[graph_name] = max_betweenness_value\n",
    "\n",
    "compute_betweenness(niche_graph_nk, \"niche_graph\", niche_nodes_list)\n",
    "compute_betweenness(almost_niche_graph_nk, \"almost_niche_graph\", almost_niche_nodes_list)\n",
    "compute_betweenness(mixed_graph_nk, \"mixed_graph\", mixed_nodes_list)\n",
    "\n",
    "avg_betweenness_list = list(avg_betweenness.values())\n",
    "max_betweenness_list = list(max_betweenness.values())\n",
    "\n",
    "centrality_df.loc[f\"Average betweenness centrality\"] = avg_betweenness_list\n",
    "centrality_df.loc[f\"Maximum betweenness centrality\"] = max_betweenness_list\n",
    "to_save = dict()\n",
    "\n",
    "to_save[\"niche_graph\"] = top10_betweenness[\"niche_graph\"]\n",
    "to_save[\"almost_niche_graph\"] = top10_betweenness[\"almost_niche_graph\"]\n",
    "to_save[\"mixed_graph\"] = top10_betweenness[\"mixed_graph\"]\n",
    "folder_name = \"analysis_5\"\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "    print(f\"Created folder {folder_name}\")\n",
    "else:\n",
    "    print(f\"Folder {folder_name} already exists\")\n",
    "with open(\"analysis_5/betweenness_centralities.json\", \"w\") as f:\n",
    "    json.dump(to_save,f)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder analysis_5 already exists\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "    print(f\"Created folder {folder_name}\")\n",
    "else:\n",
    "    print(f\"Folder {folder_name} already exists\")\n",
    "centrality_df = pd.DataFrame(columns=[\"Niche graph\", \"Almost niche graph\", \"Mixed graph\"])\n",
    "compute_centrality_nx(\"IN-degree\", nx.in_degree_centrality, centrality_df)\n",
    "compute_centrality_nx(\"OUT-degree\", nx.in_degree_centrality, centrality_df)"
   ],
   "id": "cd9efca8"
  },
  {
   "cell_type": "code",
   "id": "3fdb4341",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T01:09:35.699105Z",
     "start_time": "2026-02-14T01:07:57.136834Z"
    }
   },
   "source": [
    "import statistics\n",
    "top10_closeness = dict()\n",
    "avg_closeness = dict()\n",
    "max_closeness = dict()\n",
    "def compute_closeness(graph, graph_name, nodes_list):\n",
    "    closeness= nk.centrality.HarmonicCloseness(graph)\n",
    "    closeness.run()\n",
    "    scores = closeness.scores()\n",
    "    node_scores = list(enumerate(scores))\n",
    "    id_sorted_scores = sorted(node_scores, key=lambda x: x[1], reverse=True)\n",
    "    name_sorted_scores = list()\n",
    "    for id, score in id_sorted_scores[:10]:\n",
    "        name = nodes_list[id]\n",
    "        name_sorted_scores.append((name, score))\n",
    "    top_10= name_sorted_scores\n",
    "    avg_value = statistics.mean(scores)\n",
    "    max_value = name_sorted_scores[0][1]\n",
    "    top10_closeness[graph_name] = top_10\n",
    "    avg_closeness[graph_name] = avg_value\n",
    "    max_closeness[graph_name] = max_value\n",
    "\n",
    "compute_closeness(niche_graph_nk, \"niche_graph\", niche_nodes_list)\n",
    "compute_closeness(almost_niche_graph_nk, \"almost_niche_graph\", almost_niche_nodes_list)\n",
    "compute_closeness(mixed_graph_nk, \"mixed_graph\", mixed_nodes_list)\n",
    "\n",
    "avg_closeness_list = list(avg_closeness.values())\n",
    "max_closeness_list = list(max_closeness.values())\n",
    "\n",
    "centrality_df.loc[f\"Average closeness centrality\"] = avg_closeness_list\n",
    "centrality_df.loc[f\"Maximum closeness centrality\"] = max_closeness_list\n",
    "to_save = dict()\n",
    "\n",
    "to_save[\"niche_graph\"] = top10_closeness[\"niche_graph\"]\n",
    "to_save[\"almost_niche_graph\"] = top10_closeness[\"almost_niche_graph\"]\n",
    "to_save[\"mixed_graph\"] = top10_closeness[\"mixed_graph\"]\n",
    "folder_name = \"analysis_5\"\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "    print(f\"Created folder {folder_name}\")\n",
    "else:\n",
    "    print(f\"Folder {folder_name} already exists\")\n",
    "with open(\"analysis_5/closeness_centralities.json\", \"w\") as f:\n",
    "    json.dump(to_save,f)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder analysis_5 already exists\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T01:25:31.513976Z",
     "start_time": "2026-02-14T01:25:31.508632Z"
    }
   },
   "cell_type": "code",
   "source": "print(centrality_df)",
   "id": "14aa3de700b3c88a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Niche graph  Almost niche graph  Mixed graph\n",
      "Average closeness centrality       0.135567            0.119990     0.064286\n",
      "Maximum closeness centrality       0.297890            0.365055     0.186468\n",
      "Average pagerank centrality        0.000179            0.000026     0.000065\n",
      "Maximum pagerank centrality        0.000054            0.000011     0.000025\n",
      "Average betweenness centrality     0.000293            0.000039     0.000052\n",
      "Maximum betweenness centrality     0.048626            0.012395     0.008766\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "882d5c9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T01:38:39.076139Z",
     "start_time": "2026-02-14T01:38:37.549655Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "compute_centrality_nx(\"pagerank\", nx.pagerank, centrality_df)\n",
    "n_to_multiply = np.array([len(niche_nodes_list), len(almost_niche_nodes_list), len(mixed_nodes_list)])\n",
    "max_pr = centrality_df.loc[\"Maximum pagerank centrality\"].values\n",
    "processed_max_pr = list(max_pr*n_to_multiply)\n",
    "centrality_df.loc[\"Maximum normalized pagerank centrality\"] = processed_max_pr\n",
    "\n",
    "print(centrality_df)\n",
    "centrality_df.to_json(\"analysis_5/centrality.json\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Niche graph  Almost niche graph  \\\n",
      "Average closeness centrality               0.135567            0.119990   \n",
      "Maximum closeness centrality               0.297890            0.365055   \n",
      "Average pagerank centrality                0.000179            0.000026   \n",
      "Maximum pagerank centrality                0.000054            0.000011   \n",
      "Average betweenness centrality             0.000293            0.000039   \n",
      "Maximum betweenness centrality             0.048626            0.012395   \n",
      "Maximum normalized pagerank centrality     0.302622            0.408903   \n",
      "\n",
      "                                        Mixed graph  \n",
      "Average closeness centrality               0.064286  \n",
      "Maximum closeness centrality               0.186468  \n",
      "Average pagerank centrality                0.000065  \n",
      "Maximum pagerank centrality                0.000025  \n",
      "Average betweenness centrality             0.000052  \n",
      "Maximum betweenness centrality             0.008766  \n",
      "Maximum normalized pagerank centrality     0.388181  \n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "c0b32130",
   "metadata": {},
   "source": [
    "### NETWORK STRUCTURE"
   ]
  },
  {
   "cell_type": "code",
   "id": "d8d60601",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T03:13:55.970146Z",
     "start_time": "2026-02-14T03:13:55.301541Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "print(\"Strongly-connected components - continuous collaboration\")\n",
    "niche_scc_sets = list(nx.strongly_connected_components(niche_graph))\n",
    "niche_scc = len(max(niche_scc_sets, key=len))\n",
    "almost_niche_scc_sets = list(nx.strongly_connected_components(almost_niche_graph))\n",
    "almost_niche_scc = len(max(almost_niche_scc_sets, key=len))\n",
    "mixed_scc_sets = list(nx.strongly_connected_components(mixed_graph))\n",
    "mixed_scc = len(max(mixed_scc_sets, key=len))\n",
    "\n",
    "\n",
    "structure_df = pd.DataFrame({\"Niche graph\":niche_scc, \"Almost niche graph\":almost_niche_scc, \"Mixed graph\": mixed_scc}, index = [\"Biggest SCC size\"])\n",
    "structure_df.loc[\"Biggest SCC size ratio\"] = [niche_scc/len(niche_nodes_list), almost_niche_scc/len(almost_niche_nodes_list), mixed_scc/len(mixed_nodes_list)]\n",
    "\n",
    "print(structure_df)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strongly-connected components - continuous collaboration\n",
      "                        Niche graph  Almost niche graph  Mixed graph\n",
      "Biggest SCC size        2699.000000        18539.000000  5507.000000\n",
      "Biggest SCC size ratio     0.483259            0.480833     0.358879\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "8f1ab937",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T03:13:32.952643Z",
     "start_time": "2026-02-14T03:13:32.620732Z"
    }
   },
   "source": [
    "print(\"Weakly-connected components - isolated 'families'\")\n",
    "niche_wcc_sets = list(nx.weakly_connected_components(niche_graph))\n",
    "niche_wcc = len(max(niche_wcc_sets, key=len))\n",
    "almost_niche_wcc_sets = list(nx.weakly_connected_components(almost_niche_graph))\n",
    "almost_niche_wcc = len(max(almost_niche_wcc_sets, key=len))\n",
    "mixed_wcc_sets = list(nx.weakly_connected_components(mixed_graph))\n",
    "mixed_wcc = len(max(mixed_wcc_sets, key=len))\n",
    "\n",
    "structure_df.loc[\"Biggest WCC size\"] = [niche_wcc, almost_niche_wcc, mixed_wcc]\n",
    "structure_df.loc[\"Biggest WCC size ratio\"] = [niche_wcc/len(niche_nodes_list), almost_niche_wcc/len(almost_niche_nodes_list), mixed_wcc/len(mixed_nodes_list)]\n",
    "print(structure_df)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weakly-connected components - isolated 'families'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'structure_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[27]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      6\u001B[39m mixed_wcc_sets = \u001B[38;5;28mlist\u001B[39m(nx.weakly_connected_components(mixed_graph))\n\u001B[32m      7\u001B[39m mixed_wcc = \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mmax\u001B[39m(mixed_wcc_sets, key=\u001B[38;5;28mlen\u001B[39m))\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m \u001B[43mstructure_df\u001B[49m.loc[\u001B[33m\"\u001B[39m\u001B[33mBiggest WCC size\u001B[39m\u001B[33m\"\u001B[39m] = [niche_wcc, almost_niche_wcc, mixed_wcc]\n\u001B[32m     10\u001B[39m structure_df.loc[\u001B[33m\"\u001B[39m\u001B[33mBiggest WCC size ratio\u001B[39m\u001B[33m\"\u001B[39m] = [niche_wcc/\u001B[38;5;28mlen\u001B[39m(niche_nodes_list), almost_niche_wcc/\u001B[38;5;28mlen\u001B[39m(almost_niche_nodes_list), mixed_wcc/\u001B[38;5;28mlen\u001B[39m(mixed_nodes_list)]\n\u001B[32m     11\u001B[39m \u001B[38;5;28mprint\u001B[39m(structure_df)\n",
      "\u001B[31mNameError\u001B[39m: name 'structure_df' is not defined"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "6ddc4c5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T01:45:41.689468Z",
     "start_time": "2026-02-14T01:45:41.651501Z"
    }
   },
   "source": [
    "niche_density =nx.density(niche_graph)\n",
    "almost_niche_density = nx.density(almost_niche_graph)\n",
    "mixed_density = nx.density(mixed_graph)\n",
    "structure_df.loc[\"Density\"] = [niche_density, almost_niche_density, mixed_density]\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "c86cc33b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T01:45:55.428908Z",
     "start_time": "2026-02-14T01:45:44.090674Z"
    }
   },
   "source": [
    "print(\"Reciprocity - became famous together\")\n",
    "niche_reciprocity = nx.reciprocity(niche_graph)\n",
    "almost_niche_reciprocity = nx.reciprocity(almost_niche_graph)\n",
    "mixed_reciprocity = nx.reciprocity(mixed_graph)\n",
    "structure_df.loc[\"Reciprocity\"] = [niche_reciprocity, almost_niche_reciprocity, mixed_reciprocity]\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reciprocity - became famous together\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "5724c387",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T01:46:05.194360Z",
     "start_time": "2026-02-14T01:45:56.301105Z"
    }
   },
   "source": [
    "print(\"Transitivity\")\n",
    "# Probabilità che se A ha lavorato con B e B con C, anche A abbia lavorato con C.\n",
    "niche_transitivity = nx.transitivity(niche_graph)\n",
    "almost_niche_transitivity = nx.transitivity(almost_niche_graph)\n",
    "mixed_transitivity = nx.transitivity(mixed_graph)\n",
    "structure_df.loc[\"Transitivity\"] = [niche_transitivity, almost_niche_transitivity, mixed_transitivity]\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transitivity\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "ae199cf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T01:46:42.208158Z",
     "start_time": "2026-02-14T01:46:07.450613Z"
    }
   },
   "source": [
    "print(\"Clustering\")\n",
    "niche_clustering = nx.average_clustering(niche_graph)\n",
    "almost_niche_clustering = nx.average_clustering(almost_niche_graph)\n",
    "mixed_clustering = nx.average_clustering(mixed_graph)\n",
    "structure_df.loc[\"Clustering\"] = [niche_clustering, almost_niche_clustering, mixed_clustering]\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "2ba7edaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T01:46:44.947247Z",
     "start_time": "2026-02-14T01:46:44.943502Z"
    }
   },
   "source": [
    "structure_df.to_json(\"analysis_5/structure.json\")"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "8fd040cc",
   "metadata": {},
   "source": [
    "### ASSORTATIVITY"
   ]
  },
  {
   "cell_type": "code",
   "id": "a8696935",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T01:47:03.658331Z",
     "start_time": "2026-02-14T01:47:02.520272Z"
    }
   },
   "source": [
    "# degree assortativity\n",
    "import pandas as pd\n",
    "niche_degree_assort = nx.degree_assortativity_coefficient(niche_graph)\n",
    "almost_niche_degree_assort = nx.degree_assortativity_coefficient(almost_niche_graph)\n",
    "assortativity_df = pd.DataFrame({\"Niche graph\": niche_degree_assort, \"Almost niche graph\": almost_niche_degree_assort, \"Mixed graph\": None}, index = [\"Degree assortativity\"])\n"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "6efe9f75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T02:09:10.554871Z",
     "start_time": "2026-02-14T02:09:10.433782Z"
    }
   },
   "source": [
    "# attribute assortativity\n",
    "import pandas as pd\n",
    "mixed_attribute_assort = nx.attribute_assortativity_coefficient(mixed_graph, \"status\")\n",
    "assortativity_df.loc[\"Attribute assortativity\"] = [None, None, mixed_attribute_assort]\n",
    "assortativity_df.to_json(\"analysis_5/assortativity.json\")\n",
    "mixed_mixing_matrix = nx.attribute_mixing_matrix(mixed_graph, \"status\")"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T02:17:46.559267Z",
     "start_time": "2026-02-14T02:17:46.554326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mixed_matrix_df = pd.DataFrame({\"From almost-famous to famous actor\": mixed_mixing_matrix[0,1], \"From famous to almost-famous actor\": mixed_mixing_matrix[1,0]}, index = [\"Collaborations\"])\n",
    "print(mixed_matrix_df)\n",
    "mixed_matrix_df.to_json(\"analysis_5/mixed_matrix.json\")"
   ],
   "id": "1ead90a9983ce83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                From almost-famous to famous actor  \\\n",
      "Collaborations                            0.634302   \n",
      "\n",
      "                From famous to almost-famous actor  \n",
      "Collaborations                            0.365698  \n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### DISTANCE METRICS",
   "id": "c28d4b5e9d8153dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T03:05:36.462359Z",
     "start_time": "2026-02-14T03:05:36.455793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import networkit as nk\n",
    "distance_df = pd.DataFrame(columns=[\"Niche graph\", \"Almost niche graph\", \"Mixed graph\"])\n",
    "diameter_list= list()\n",
    "avg_sp = list()\n",
    "def small_world_analysis(main_component, graph_name):\n",
    "    main_component = nk.nxadapter.nx2nk(main_component)\n",
    "    print(\"Main component number of nodes:\", main_component.numberOfNodes())\n",
    "    print(\"Main component number of edges:\", main_component.numberOfEdges())\n",
    "    print(\"Analysing the diameter...\")\n",
    "    diameter = nk.distance.Diameter(main_component, algo=nk.distance.DiameterAlgo.EXACT)\n",
    "    diameter.run()\n",
    "    diameter_value = diameter.getDiameter()\n",
    "    print(\"Diameter:\", diameter_value[0])\n",
    "    diameter_list.append(diameter_value[0])\n",
    "    print(\"Computing the average path length (sampled)...\")\n",
    "    all_nodes = list(main_component.iterNodes())\n",
    "    sampled_nodes = all_nodes\n",
    "    batch_size = 200\n",
    "    num_batches = math.ceil(len(all_nodes) / batch_size)\n",
    "    total_distance_sum = 0\n",
    "    total_valid_pairs = 0\n",
    "    print(\"Number of batches:\", num_batches)\n",
    "    #for node in main_component.iterNodes():\n",
    "    for batch_iter in range(num_batches):\n",
    "        start_idx = batch_iter * batch_size\n",
    "        end_idx = min((batch_iter + 1) * batch_size, len(all_nodes))\n",
    "        batch_nodes = sampled_nodes[start_idx:end_idx]\n",
    "\n",
    "        spsp = nk.distance.SPSP(main_component, batch_nodes)\n",
    "        spsp.run()\n",
    "        distances_from_source = spsp.getDistances()\n",
    "\n",
    "        distances_array = np.array(distances_from_source)\n",
    "        valid_mask = distances_array > 0\n",
    "        total_distance_sum += distances_array[valid_mask].sum()\n",
    "        total_valid_pairs += valid_mask.sum()\n",
    "\n",
    "        del spsp\n",
    "        del distances_array\n",
    "        if batch_iter % 10 == 0 and batch_iter != 0:\n",
    "            print(\"Finished batch:\", batch_iter)\n",
    "\n",
    "    avg_path_length = total_distance_sum / total_valid_pairs\n",
    "    print(\"Average sampled path length:\", avg_path_length)\n",
    "    avg_sp.append(avg_path_length)\n",
    "\n"
   ],
   "id": "2ad5a0138966b4cc",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T03:02:43.537787Z",
     "start_time": "2026-02-14T03:02:28.585117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import networkx as nx\n",
    "niche_main_cc = max(nx.weakly_connected_components(niche_graph), key = len)\n",
    "niche_main_cc = niche_graph.subgraph(niche_main_cc).copy()\n",
    "niche_main_cc = niche_main_cc.to_undirected()\n",
    "almost_niche_main_cc = max(nx.weakly_connected_components(almost_niche_graph), key = len)\n",
    "almost_niche_main_cc = almost_niche_graph.subgraph(almost_niche_main_cc).copy()\n",
    "almost_niche_main_cc = almost_niche_main_cc.to_undirected()\n",
    "mixed_main_cc = max(nx.weakly_connected_components(mixed_graph), key = len)\n",
    "mixed_main_cc = mixed_graph.subgraph(mixed_main_cc).copy()\n",
    "mixed_main_cc = mixed_main_cc.to_undirected()\n",
    "\n"
   ],
   "id": "a01dff3256a5c3c7",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T03:07:59.947114Z",
     "start_time": "2026-02-14T03:05:39.645673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "small_world_analysis(niche_main_cc, \"niche main component\")\n",
    "small_world_analysis(almost_niche_main_cc, \"almost_niche main component\")\n",
    "small_world_analysis(mixed_main_cc, \"mixed main component\")"
   ],
   "id": "241dec0c3b543e56",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main component number of nodes: 5585\n",
      "Main component number of edges: 28420\n",
      "Analysing the diameter...\n",
      "Diameter: 6\n",
      "Computing the average path length (sampled)...\n",
      "Number of batches: 28\n",
      "Finished batch: 10\n",
      "Finished batch: 20\n",
      "Average sampled path length: 3.5392139069806814\n",
      "Main component number of nodes: 38014\n",
      "Main component number of edges: 558631\n",
      "Analysing the diameter...\n",
      "Diameter: 11\n",
      "Computing the average path length (sampled)...\n",
      "Number of batches: 191\n",
      "Finished batch: 10\n",
      "Finished batch: 20\n",
      "Finished batch: 30\n",
      "Finished batch: 40\n",
      "Finished batch: 50\n",
      "Finished batch: 60\n",
      "Finished batch: 70\n",
      "Finished batch: 80\n",
      "Finished batch: 90\n",
      "Finished batch: 100\n",
      "Finished batch: 110\n",
      "Finished batch: 120\n",
      "Finished batch: 130\n",
      "Finished batch: 140\n",
      "Finished batch: 150\n",
      "Finished batch: 160\n",
      "Finished batch: 170\n",
      "Finished batch: 180\n",
      "Finished batch: 190\n",
      "Average sampled path length: 3.910698588297274\n",
      "Main component number of nodes: 9979\n",
      "Main component number of edges: 69565\n",
      "Analysing the diameter...\n",
      "Diameter: 6\n",
      "Computing the average path length (sampled)...\n",
      "Number of batches: 50\n",
      "Finished batch: 10\n",
      "Finished batch: 20\n",
      "Finished batch: 30\n",
      "Finished batch: 40\n",
      "Average sampled path length: 3.7540411131164584\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T03:08:30.001897Z",
     "start_time": "2026-02-14T03:08:29.993123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "distance_df.loc[\"Diameter\"] = diameter_list\n",
    "distance_df.loc[\"Main connected component shortest path\"] = avg_sp\n",
    "\n",
    "\n"
   ],
   "id": "e9302a67f36d0278",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T03:15:38.690941Z",
     "start_time": "2026-02-14T03:15:38.454212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "distance_df.loc[\"Graph - number of nodes\"] = [len(list(niche_graph.nodes())), len(list(almost_niche_graph.nodes())), len(list(mixed_graph.nodes()))]\n",
    "distance_df.loc[\"Graph - number of edges\"] = [len(list(niche_graph.edges())), len(list(almost_niche_graph.edges())), len(list(mixed_graph.edges()))]\n",
    "distance_df.loc[\"Number of connected components\"] = [len(niche_wcc_sets), len(almost_niche_wcc_sets), len(mixed_wcc_sets)]\n",
    "distance_df.to_json(\"analysis_5/distance.json\")"
   ],
   "id": "b3237c4edc9f98f2",
   "outputs": [],
   "execution_count": 33
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_mining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
