{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "140881fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:11:39.025981Z",
     "start_time": "2026-02-14T06:10:54.370762Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import networkx as nx\n",
    "with open(\"actors_projection_graph.json\") as f:\n",
    "    graph_dict = json.load(f)\n",
    "\n",
    "graph = nx.node_link_graph(graph_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "978c01e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:12:11.846748Z",
     "start_time": "2026-02-14T06:12:11.571356Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"successful_actors.json\") as f:\n",
    "    successful = json.load(f)\n",
    "with open(\"almost_successful_actors.json\") as f:\n",
    "    almost_successful = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eef252a24df7401e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:12:12.948538Z",
     "start_time": "2026-02-14T06:12:12.943754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453\n",
      "14892\n"
     ]
    }
   ],
   "source": [
    "print(len(successful))\n",
    "print(len(almost_successful))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c90a2a7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T01:01:52.825048Z",
     "start_time": "2026-02-14T01:01:52.821724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gender': 'male', 'countries': ['Hungary', 'Germany', 'India', 'Mexico', 'United States of America', 'France', 'United Kingdom', 'Singapore', 'Australia', 'Italy', 'Hong Kong', 'Malta'], 'avg_movie_revenue_2020_$': 97984814, 'top_ten': [[1995, 'movie: Toy Story'], [1995, 'movie: Apollo 13'], [1994, 'movie: Forrest Gump'], [1993, 'movie: Philadelphia'], [1993, 'movie: Sleepless in Seattle'], [1996, 'movie: That Thing You Do!'], [1998, 'movie: Saving Private Ryan'], [1989, \"movie: The 'Burbs\"], [1984, 'movie: Splash'], [1986, 'movie: The Money Pit'], [1986, 'movie: Nothing in Common'], [1998, \"movie: You've Got Mail\"], [1988, 'movie: Big'], [1999, 'movie: Return with Honor'], [1999, 'movie: Toy Story 2'], [1990, 'movie: The Bonfire of the Vanities'], [1999, 'movie: The Green Mile'], [1992, 'movie: A League of Their Own'], [1985, 'movie: Volunteers'], [1984, 'movie: Bachelor Party'], [1988, 'movie: Punchline'], [2000, 'movie: Cast Away'], [1989, 'movie: Turner & Hooch'], [1980, \"movie: He Knows You're Alone\"], [1990, 'movie: Joe Versus the Volcano'], [2002, 'movie: Road to Perdition'], [2002, 'movie: Catch Me If You Can'], [1992, 'movie: Radio Flyer'], [1987, 'movie: Dragnet'], [2004, 'movie: The Ladykillers (2004)'], [2004, 'movie: The Terminal'], [1985, 'movie: The Man with One Red Shoe'], [2004, 'movie: The Polar Express'], [1998, 'movie: From the Earth to the Moon'], [2006, 'movie: The Da Vinci Code'], [2006, 'movie: Who Killed the Electric Car?'], [2007, \"movie: Charlie Wilson's War\"], [2008, 'movie: The Great Buck Howard'], [2009, 'movie: Angels & Demons'], [2000, 'movie: Shooting War'], [2010, 'movie: Toy Story 3'], [2007, 'movie: The Pixar Story'], [2011, 'movie: Larry Crowne'], [2011, 'movie: Extremely Loud & Incredibly Close'], [2007, 'movie: The War (2007)'], [2012, 'movie: Cloud Atlas'], [2013, 'movie: Captain Phillips'], [2013, 'movie: Toy Story of Terror!'], [2013, 'movie: Saving Mr. Banks'], [2013, 'movie: Killing Lincoln'], [2011, 'movie: Hawaiian Vacation'], [2004, 'movie: Elvis Has Left the Building'], [2012, 'movie: Partysaurus Rex'], [2014, 'movie: Toy Story That Time Forgot'], [2014, 'movie: And the Oscar Goes To...'], [2017, 'movie: The Circle (2017)'], [2015, 'movie: Bridge of Spies'], [2015, 'movie: Everything Is Copy'], [2013, 'movie: The Sixties'], [2016, 'movie: A Hologram for the King'], [2011, 'movie: The Extraordinary Voyage'], [2016, 'movie: Sully'], [2016, 'movie: Inferno (2016)'], [2011, 'movie: Prohibition'], [2015, 'movie: Ithaca']], 'genre': 'Comedy', 'all_genres': ['Comedy', 'Drama', 'Documentary', 'Family', 'Animation', 'Thriller', 'Romance', 'History', 'Fantasy', 'Crime', 'Action', 'War', 'Adventure', 'Science Fiction', 'Horror', 'Mystery', 'Foreign', 'TV Movie'], 'period': 'new_hollywood', 'bipartite': 1, 'breakthrough': 1988, 'oscar_nomination': True, 'successive_noms': 5, 'post_breakthrough_movies_year': [[1989, 2], [1990, 2], [1992, 2], [1993, 2], [1994, 1], [1995, 2], [1996, 1], [1998, 3], [1999, 2], [2000, 2], [2002, 2], [2004, 4], [2006, 2], [2007, 3], [2008, 1], [2009, 1], [2010, 1], [2011, 4], [2012, 2], [2013, 4], [2014, 2], [2015, 3], [2016, 3], [2017, 1]], 'best_period': '1991-2000'}\n"
     ]
    }
   ],
   "source": [
    "print(successful[\"actor: Tom Hanks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "955d7dce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:12:42.092464Z",
     "start_time": "2026-02-14T06:12:37.399662Z"
    }
   },
   "outputs": [],
   "source": [
    "nodes = [(n,d) for n, d in graph.nodes(data=True)]\n",
    "edges = [(e1,e2,d) for e1,e2, d in graph.edges(data=True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "732292f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T00:11:09.193567Z",
     "start_time": "2026-02-14T00:11:09.189644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('actor: Tom Hanks', 'actor: Kamron Leal', {'weight': 1, 'movies': [['movie: Sully', 2016]], 'earliest_contact': 2016})\n",
      "('actor: Tom Hanks', {'gender': 'male', 'countries': ['Hungary', 'Germany', 'India', 'Mexico', 'United States of America', 'France', 'United Kingdom', 'Singapore', 'Australia', 'Italy', 'Hong Kong', 'Malta'], 'avg_movie_revenue_2020_$': 97984814, 'top_ten': [[1995, 'movie: Toy Story'], [1995, 'movie: Apollo 13'], [1994, 'movie: Forrest Gump'], [1993, 'movie: Philadelphia'], [1993, 'movie: Sleepless in Seattle'], [1996, 'movie: That Thing You Do!'], [1998, 'movie: Saving Private Ryan'], [1989, \"movie: The 'Burbs\"], [1984, 'movie: Splash'], [1986, 'movie: The Money Pit'], [1986, 'movie: Nothing in Common'], [1998, \"movie: You've Got Mail\"], [1988, 'movie: Big'], [1999, 'movie: Return with Honor'], [1999, 'movie: Toy Story 2'], [1990, 'movie: The Bonfire of the Vanities'], [1999, 'movie: The Green Mile'], [1992, 'movie: A League of Their Own'], [1985, 'movie: Volunteers'], [1984, 'movie: Bachelor Party'], [1988, 'movie: Punchline'], [2000, 'movie: Cast Away'], [1989, 'movie: Turner & Hooch'], [1980, \"movie: He Knows You're Alone\"], [1990, 'movie: Joe Versus the Volcano'], [2002, 'movie: Road to Perdition'], [2002, 'movie: Catch Me If You Can'], [1992, 'movie: Radio Flyer'], [1987, 'movie: Dragnet'], [2004, 'movie: The Ladykillers (2004)'], [2004, 'movie: The Terminal'], [1985, 'movie: The Man with One Red Shoe'], [2004, 'movie: The Polar Express'], [1998, 'movie: From the Earth to the Moon'], [2006, 'movie: The Da Vinci Code'], [2006, 'movie: Who Killed the Electric Car?'], [2007, \"movie: Charlie Wilson's War\"], [2008, 'movie: The Great Buck Howard'], [2009, 'movie: Angels & Demons'], [2000, 'movie: Shooting War'], [2010, 'movie: Toy Story 3'], [2007, 'movie: The Pixar Story'], [2011, 'movie: Larry Crowne'], [2011, 'movie: Extremely Loud & Incredibly Close'], [2007, 'movie: The War (2007)'], [2012, 'movie: Cloud Atlas'], [2013, 'movie: Captain Phillips'], [2013, 'movie: Toy Story of Terror!'], [2013, 'movie: Saving Mr. Banks'], [2013, 'movie: Killing Lincoln'], [2011, 'movie: Hawaiian Vacation'], [2004, 'movie: Elvis Has Left the Building'], [2012, 'movie: Partysaurus Rex'], [2014, 'movie: Toy Story That Time Forgot'], [2014, 'movie: And the Oscar Goes To...'], [2017, 'movie: The Circle (2017)'], [2015, 'movie: Bridge of Spies'], [2015, 'movie: Everything Is Copy'], [2013, 'movie: The Sixties'], [2016, 'movie: A Hologram for the King'], [2011, 'movie: The Extraordinary Voyage'], [2016, 'movie: Sully'], [2016, 'movie: Inferno (2016)'], [2011, 'movie: Prohibition'], [2015, 'movie: Ithaca']], 'genre': 'Comedy', 'all_genres': ['Comedy', 'Drama', 'Documentary', 'Family', 'Animation', 'Thriller', 'Romance', 'History', 'Fantasy', 'Crime', 'Action', 'War', 'Adventure', 'Science Fiction', 'Horror', 'Mystery', 'Foreign', 'TV Movie'], 'period': 'new_hollywood', 'bipartite': 1, 'breakthrough': 1988, 'oscar_nomination': True, 'successive_noms': 5, 'post_breakthrough_movies_year': [[1989, 2], [1990, 2], [1992, 2], [1993, 2], [1994, 1], [1995, 2], [1996, 1], [1998, 3], [1999, 2], [2000, 2], [2002, 2], [2004, 4], [2006, 2], [2007, 3], [2008, 1], [2009, 1], [2010, 1], [2011, 4], [2012, 2], [2013, 4], [2014, 2], [2015, 3], [2016, 3], [2017, 1]], 'best_period': '1991-2000', 'contacts_before_breakthrough': [['actor: Allan Arbus', 1985], ['actor: Elizabeth Kemp', 1980], ['actor: Edward Herrmann', 1985], ['actor: Florence Schauffler', 1984], ['actor: Dortha Duckworth', 1985], ['actor: Elizabeth Ashley', 1987], ['actor: Frank Hamilton', 1985], ['actor: Frankie Faison', 1986], ['actor: Irving Metzman', 1985], ['actor: Billy Beck', 1984], ['actor: William Tepper', 1984], ['actor: Tom Toner', 1984], ['actor: Monique Gabrielle', 1984], ['actor: Gary Grossman', 1984], ['actor: Alexandra Paul', 1987], ['actor: Shelley Long', 1986], ['actor: Dody Goodman', 1984], ['actor: Howard Morris', 1984], ['actor: Jim Belushi', 1985], ['actor: Rebecca Perle', 1984], ['actor: Steve James', 1980], ['actor: Anne Gaybis', 1984], ['actor: Damita Jo Freeman', 1985], ['actor: Ernest Harada', 1985], ['actor: Philip Bosco', 1986], ['actor: Dabney Coleman', 1985], ['actor: Tom Noonan', 1985], ['actor: Alexander Godunov', 1986], ['actor: Adrian Zmed', 1984], ['actor: Dan Castellaneta', 1986], ['actor: Carrie Fisher', 1985], ['actor: Art LaFleur', 1985], ['actor: Mark Robman', 1985], [\"actor: Jack O'Halloran\", 1987], ['actor: Sam Sako', 1985], ['actor: Robert Prescott', 1984], ['actor: Xander Berkeley', 1985], ['actor: Christopher Plummer', 1987], ['actor: Nestor Serrano', 1986], ['actor: Gedde Watanabe', 1985], ['actor: Tom Rolfing', 1980], ['actor: Douglass Watson', 1986], ['actor: Rita Wilson', 1985], ['actor: Héctor Elizondo', 1986], ['actor: Eugene Levy', 1984], ['actor: John Candy', 1984], ['actor: James Carroll', 1980], ['actor: Charles Durning', 1985], ['actor: James Rebhorn', 1980], ['actor: Jackie Gleason', 1986], ['actor: Bradford Bancroft', 1984], ['actor: Tom Rayhall', 1985], ['actor: Johnny Yune', 1986], ['actor: Ivy Bethune', 1985], ['actor: Sela Ward', 1986], ['actor: Tim Thomerson', 1985], ['actor: Shannon Tweed', 1987], ['actor: Julius Carry', 1985], ['actor: Patsy Pease', 1980], ['actor: Maureen Stapleton', 1986], ['actor: David Selburg', 1985], ['actor: John Bloom', 1984], ['actor: Richard McGonagle', 1985], ['actor: Dana Barron', 1980], ['actor: Ritch Brinkley', 1985], ['actor: Lisa London', 1987], ['actor: Bobby Di Cicco', 1984], ['actor: Stephen Bradley', 1985], ['actor: Lori Singer', 1985], ['actor: Barbara Stuart', 1984], ['actor: Angela Aames', 1984], ['actor: Fred Lerner', 1984], ['actor: George Plimpton', 1985], ['actor: Lewis Arlt', 1980], ['actor: Joe Mantegna', 1986], ['actor: Dan Resin', 1985], ['actor: Barry Corbin', 1986], ['actor: Jake Steinfeld', 1986], ['actor: Jeff Ware', 1985], ['actor: Michael Dudikoff', 1984], ['actor: Daryl Hannah', 1984], ['actor: David L. Lander', 1985], ['actor: Richard B. Shull', 1984], ['actor: Michael Jeter', 1986], ['actor: Ji-Tu Cumbuka', 1984], ['actor: George Grizzard', 1984], ['actor: Shecky Greene', 1984], ['actor: Yakov Smirnoff', 1986], ['actor: Wendie Jo Sperber', 1984], [\"actor: Caitlin O'Heaney\", 1980], ['actor: David Ogden Stiers', 1985], ['actor: Barry Diamond', 1984], ['actor: Paul Gleason', 1980], ['actor: Dan Aykroyd', 1987], ['actor: Richard Clark', 1985], ['actor: Wendell Pierce', 1986], ['actor: Don Scardino', 1980], ['actor: Tawny Kitaen', 1984], ['actor: Charles Walker', 1985], ['actor: Carmine Caridi', 1986], ['actor: Kathleen Freeman', 1987], ['actor: Noel De Souza', 1985], ['actor: Victoria Carroll', 1985], ['actor: Mike Hagerty', 1986], ['actor: Tracy Reiner', 1986], ['actor: Mia Dillon', 1986], ['actor: Tom Chiu', 1985], ['actor: Deborah Harmon', 1984], ['actor: Billy Lombardo', 1986], ['actor: Lowell Ganz', 1984], ['actor: Tetchie Agbayani', 1986], ['actor: Harry Morgan', 1987], ['actor: Brian Backer', 1986], ['actor: Joseph Leon', 1980], ['actor: Gerrit Graham', 1985], ['actor: Babaloo Mandel', 1984], ['actor: Bess Armstrong', 1986], ['actor: Lucille Dobrin', 1986], ['actor: Dan Ziskie', 1985], ['actor: Brett Baxter Clark', 1984], ['actor: Toni Alessandrini', 1984], ['actor: John van Dreelen', 1986], ['actor: Eva Marie Saint', 1986], ['actor: Conrad Janis', 1986], ['actor: Rosanne Katon', 1984], ['actor: Lisa Raggio', 1985], ['actor: George Martin', 1985], ['actor: Tracy Smith', 1984], ['actor: Michele Starck', 1984], ['actor: Leslie West', 1986], ['actor: Charles Levin', 1985], ['actor: Patricia Gaul', 1985], ['actor: Josh Mostel', 1986]]})\n"
     ]
    }
   ],
   "source": [
    "print(edges[0])\n",
    "print(nodes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6c0399c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:15:54.219814Z",
     "start_time": "2026-02-14T06:15:52.495786Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's create a graph with only the most successful actors to see how they connect to each other\n",
    "\n",
    "niche_graph = nx.DiGraph()\n",
    "for actor,diz in successful.items():\n",
    "    niche_graph.add_node(actor, **diz)\n",
    "\n",
    "for edge in edges:\n",
    "    actor1 = edge[0]\n",
    "    actor2 = edge[1]\n",
    "    if actor1 in successful and actor2 in successful:\n",
    "        if \"contacts_before_breakthrough\" in graph.nodes[actor1]:\n",
    "            for colleague in graph.nodes[actor1][\"contacts_before_breakthrough\"]:\n",
    "                if actor2 == colleague[0]:\n",
    "                    niche_graph.add_edge(actor1, actor2, **{\"year\":colleague[1]})\n",
    "        if \"contacts_before_breakthrough\" in graph.nodes[actor2]:\n",
    "            for colleague in graph.nodes[actor2][\"contacts_before_breakthrough\"]:\n",
    "                if actor1 == colleague[0]:\n",
    "                    niche_graph.add_edge(actor2, actor1, **{\"year\":colleague[1]})\n",
    "\n",
    "to_dump = nx.readwrite.json_graph.node_link_data(niche_graph)\n",
    "with open(\"niche_graph.json\", \"w\") as f:\n",
    "    json.dump(to_dump, f, indent = 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dedaab6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:16:39.512936Z",
     "start_time": "2026-02-14T06:16:21.216092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14892\n"
     ]
    }
   ],
   "source": [
    "# let's create a graph with only non-successful actors to see how they connect to each other\n",
    "\n",
    "almost_niche_graph = nx.DiGraph()\n",
    "for actor,diz in almost_successful.items():\n",
    "    almost_niche_graph.add_node(actor, **diz)\n",
    "\n",
    "for edge in edges:\n",
    "    actor1 = edge[0]\n",
    "    actor2 = edge[1]\n",
    "    if actor1 in almost_successful and actor2 in almost_successful:\n",
    "        if \"contacts_before_breakthrough\" in graph.nodes[actor1]:\n",
    "            for colleague in graph.nodes[actor1][\"contacts_before_breakthrough\"]:\n",
    "                if actor2 == colleague[0]:\n",
    "                    almost_niche_graph.add_edge(actor1, actor2, **{\"year\":colleague[1]})\n",
    "        if \"contacts_before_breakthrough\" in graph.nodes[actor2]:\n",
    "            for colleague in graph.nodes[actor2][\"contacts_before_breakthrough\"]:\n",
    "                if actor1 == colleague[0]:\n",
    "                    almost_niche_graph.add_edge(actor2, actor1, **{\"year\":colleague[1]})\n",
    "\n",
    "\n",
    "to_dump = nx.readwrite.json_graph.node_link_data(almost_niche_graph)\n",
    "with open(\"almost_niche_graph.json\", \"w\") as f:\n",
    "    json.dump(to_dump, f, indent = 4)\n",
    "print(len(almost_niche_graph))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d043bd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:17:14.288135Z",
     "start_time": "2026-02-14T06:17:06.917697Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's create a bipartite graph with the most successful actors and those who almost made it to see how they connect to each other\n",
    "\n",
    "\n",
    "mixed_graph = nx.DiGraph()\n",
    "for actor,diz in successful.items():\n",
    "    diz[\"status\"] = \"successful\"\n",
    "    mixed_graph.add_node(actor, **diz, bipartite=0)\n",
    "for actor,diz in almost_successful.items():\n",
    "    diz[\"status\"] = \"almost_successful\"\n",
    "    mixed_graph.add_node(actor, **diz, bipartite =1)\n",
    "\n",
    "for edge in edges:\n",
    "    actor1 = edge[0]\n",
    "    actor2 = edge[1]\n",
    "    if actor1 in almost_successful and actor2 in successful:\n",
    "        if \"contacts_before_breakthrough\" in graph.nodes[actor1]:\n",
    "            for colleague in graph.nodes[actor1][\"contacts_before_breakthrough\"]:\n",
    "                if actor2 == colleague[0]:\n",
    "                    mixed_graph.add_edge(actor1, actor2, **{\"year\":colleague[1]})\n",
    "        if \"contacts_before_breakthrough\" in graph.nodes[actor2]:\n",
    "            for colleague in graph.nodes[actor2][\"contacts_before_breakthrough\"]:\n",
    "                if actor1 == colleague[0]:\n",
    "                    mixed_graph.add_edge(actor2, actor1, **{\"year\":colleague[1]})\n",
    "    if actor1 in successful and actor2 in almost_successful:\n",
    "        if \"contacts_before_breakthrough\" in graph.nodes[actor1]:\n",
    "            for colleague in graph.nodes[actor1][\"contacts_before_breakthrough\"]:\n",
    "                if actor2 == colleague[0]:\n",
    "                    mixed_graph.add_edge(actor1, actor2, **{\"year\":colleague[1]})\n",
    "        if \"contacts_before_breakthrough\" in graph.nodes[actor2]:\n",
    "            for colleague in graph.nodes[actor2][\"contacts_before_breakthrough\"]:\n",
    "                if actor1 == colleague[0]:\n",
    "                    mixed_graph.add_edge(actor2, actor1, **{\"year\": colleague[1]})\n",
    "\n",
    "\n",
    "\n",
    "to_dump = nx.readwrite.json_graph.node_link_data(mixed_graph)\n",
    "with open(\"mixed_graph.json\", \"w\") as f:\n",
    "    json.dump(to_dump, f, indent = 4)\n",
    "\n",
    "if nx.bipartite.is_bipartite(mixed_graph):\n",
    "    print(\"Il grafo è bipartito correttamente.\")\n",
    "else:\n",
    "    print(\"Errore: ci sono archi interni ai set!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab77926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find mentors, mentees and peers\n",
    "# mentor: someone who has an edge incoming from someone, but not one outgoing to that someone\n",
    "# mentor: someone who has an edge outgoing to someone, but not one incoming from that someone\n",
    "# peers: actors who knew each other before either made it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389bcba4",
   "metadata": {},
   "source": [
    "# ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2398ff96",
   "metadata": {},
   "source": [
    "### CENTRALITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c38c01b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:18:03.863231Z",
     "start_time": "2026-02-14T06:18:03.034765Z"
    }
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "import pandas as pd\n",
    "\n",
    "def compute_centrality_nx(kind, function,df):\n",
    "    niche_betweenness = function(niche_graph)\n",
    "    almost_niche_betweenness = function(almost_niche_graph)\n",
    "    mixed_betweenness = function(mixed_graph)\n",
    "\n",
    "    items_niche_betweenness = niche_betweenness.items()\n",
    "    top_10_niche_betweenness = sorted(items_niche_betweenness, key = lambda x: x[1], reverse = True)[:10]\n",
    "    avg_niche_betweenness = statistics.mean([value for name, value in niche_betweenness.items()])\n",
    "    max_niche_betweenness = max([value for name,value in top_10_niche_betweenness])\n",
    "\n",
    "    items_almost_niche_betweenness = almost_niche_betweenness.items()\n",
    "    top_10_almost_niche_betweenness  = sorted(items_almost_niche_betweenness, key = lambda x: x[1], reverse = True)[:10]\n",
    "    avg_almost_niche_betweenness= statistics.mean([value for name, value in almost_niche_betweenness.items()])\n",
    "    max_almost_niche_betweenness = max([value for name,value in top_10_almost_niche_betweenness])\n",
    "\n",
    "    items_mixed_betweenness= mixed_betweenness.items()\n",
    "    top_10_mixed_betweenness  = sorted(items_mixed_betweenness, key = lambda x: x[1], reverse = True)[:10]\n",
    "    avg_mixed_betweenness = statistics.mean([value for name, value in mixed_betweenness.items()])\n",
    "    max_mixed_betweenness = max([value for name,value in top_10_mixed_betweenness])\n",
    "\n",
    "    df.loc[f\"Average {kind} centrality\"] = [avg_niche_betweenness, avg_almost_niche_betweenness, avg_mixed_betweenness]\n",
    "    df.loc[f\"Maximum {kind} centrality\"] = [max_niche_betweenness, max_almost_niche_betweenness, max_mixed_betweenness]\n",
    "\n",
    "\n",
    "    to_save = dict()\n",
    "    to_save[\"niche_graph\"] = top_10_niche_betweenness\n",
    "    to_save[\"almost_niche_graph\"] = top_10_almost_niche_betweenness\n",
    "    to_save[\"mixed_graph\"] = top_10_mixed_betweenness\n",
    "\n",
    "    # with open(f\"analysis_5/{kind}_centralities.json\", \"w\") as f:\n",
    "    #     json.dump(to_save,f, indent=4)\n",
    "centrality_df = pd.DataFrame(columns=[\"Niche graph\", \"Almost niche graph\", \"Mixed graph\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9153c18a91f443",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:18:08.515285Z",
     "start_time": "2026-02-14T06:18:06.166194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Niche graph, Almost niche graph, Mixed graph]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkit as nk\n",
    "centrality_df = pd.DataFrame(columns=[\"Niche graph\", \"Almost niche graph\", \"Mixed graph\"])\n",
    "centrality_df = pd.read_json(\"analysis_5/centrality.json\")\n",
    "print(centrality_df)\n",
    "niche_nodes_list = list(niche_graph.nodes())\n",
    "almost_niche_nodes_list = list(almost_niche_graph.nodes())\n",
    "mixed_nodes_list = list(mixed_graph.nodes())\n",
    "nk.setNumberOfThreads(7)\n",
    "niche_graph_nk = nk.nxadapter.nx2nk(niche_graph)\n",
    "almost_niche_graph_nk = nk.nxadapter.nx2nk(almost_niche_graph)\n",
    "mixed_graph_nk = nk.nxadapter.nx2nk(mixed_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec4bff04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:18:41.925053Z",
     "start_time": "2026-02-14T06:18:12.986161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder analysis_5 already exists\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "import pandas as pd\n",
    "import networkit as nk\n",
    "import os\n",
    "\n",
    "\n",
    "top10_betweenness = dict()\n",
    "avg_betweenness = dict()\n",
    "max_betweenness = dict()\n",
    "\n",
    "def compute_betweenness(graph, graph_name, nodes_list):\n",
    "    betweenness = nk.centrality.Betweenness(graph, normalized=True)\n",
    "    betweenness.run()\n",
    "    scores = betweenness.scores()\n",
    "    node_scores = list(enumerate(scores))\n",
    "    #print(scores)\n",
    "    id_sorted_scores = sorted(node_scores, key=lambda x: x[1], reverse=True)\n",
    "    name_sorted_scores = list()\n",
    "    for id, score in id_sorted_scores[:10]:\n",
    "        name = nodes_list[id]\n",
    "        name_sorted_scores.append((name, score))\n",
    "    top_10_betweenness = name_sorted_scores\n",
    "    avg_betweenness_value = statistics.mean(scores)\n",
    "    max_betweenness_value = name_sorted_scores[0][1]\n",
    "    top10_betweenness[graph_name] = top_10_betweenness\n",
    "    avg_betweenness[graph_name] = avg_betweenness_value\n",
    "    max_betweenness[graph_name] = max_betweenness_value\n",
    "\n",
    "compute_betweenness(niche_graph_nk, \"niche_graph\", niche_nodes_list)\n",
    "compute_betweenness(almost_niche_graph_nk, \"almost_niche_graph\", almost_niche_nodes_list)\n",
    "compute_betweenness(mixed_graph_nk, \"mixed_graph\", mixed_nodes_list)\n",
    "\n",
    "avg_betweenness_list = list(avg_betweenness.values())\n",
    "max_betweenness_list = list(max_betweenness.values())\n",
    "\n",
    "centrality_df.loc[f\"Average betweenness centrality\"] = avg_betweenness_list\n",
    "centrality_df.loc[f\"Maximum betweenness centrality\"] = max_betweenness_list\n",
    "to_save = dict()\n",
    "\n",
    "to_save[\"niche_graph\"] = top10_betweenness[\"niche_graph\"]\n",
    "to_save[\"almost_niche_graph\"] = top10_betweenness[\"almost_niche_graph\"]\n",
    "to_save[\"mixed_graph\"] = top10_betweenness[\"mixed_graph\"]\n",
    "folder_name = \"analysis_5\"\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "    print(f\"Created folder {folder_name}\")\n",
    "else:\n",
    "    print(f\"Folder {folder_name} already exists\")\n",
    "with open(\"analysis_5/betweenness_centralities.json\", \"w\") as f:\n",
    "    json.dump(to_save,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3f73c020343381d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:18:44.497533Z",
     "start_time": "2026-02-14T06:18:44.491765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Niche graph  Almost niche graph  Mixed graph\n",
      "Average betweenness centrality     0.004591            0.000092     0.000052\n",
      "Maximum betweenness centrality     0.086162            0.022253     0.008766\n"
     ]
    }
   ],
   "source": [
    "print(centrality_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd9efca8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:18:46.622224Z",
     "start_time": "2026-02-14T06:18:46.448102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder analysis_5 already exists\n",
      "                               Niche graph  Almost niche graph  Mixed graph\n",
      "Average IN-degree centrality      0.022803            0.001980     0.000353\n",
      "Maximum IN-degree centrality      0.075221            0.042710     0.021051\n",
      "Average OUT-degree centrality     0.022803            0.001980     0.000353\n",
      "Maximum OUT-degree centrality     0.137168            0.048284     0.026786\n"
     ]
    }
   ],
   "source": [
    "folder_name = \"analysis_5\"\n",
    "\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "    print(f\"Created folder {folder_name}\")\n",
    "else:\n",
    "    print(f\"Folder {folder_name} already exists\")\n",
    "compute_centrality_nx(\"IN-degree\", nx.in_degree_centrality, centrality_df)\n",
    "compute_centrality_nx(\"OUT-degree\", nx.out_degree_centrality, centrality_df)\n",
    "print(centrality_df)\n",
    "centrality_df.to_json(\"analysis_5/ndejf.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdb4341",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:19:19.619196Z",
     "start_time": "2026-02-14T06:18:57.290017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder analysis_5 already exists\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "top10_closeness = dict()\n",
    "avg_closeness = dict()\n",
    "max_closeness = dict()\n",
    "def compute_closeness(graph, graph_name, nodes_list):\n",
    "    closeness= nk.centrality.HarmonicCloseness(graph)\n",
    "    closeness.run()\n",
    "    scores = closeness.scores()\n",
    "    node_scores = list(enumerate(scores))\n",
    "    id_sorted_scores = sorted(node_scores, key=lambda x: x[1], reverse=True)\n",
    "    name_sorted_scores = list()\n",
    "    for id, score in id_sorted_scores[:10]:\n",
    "        name = nodes_list[id]\n",
    "        name_sorted_scores.append((name, score))\n",
    "    top_10= name_sorted_scores\n",
    "    avg_value = statistics.mean(scores)\n",
    "    max_value = name_sorted_scores[0][1]\n",
    "    top10_closeness[graph_name] = top_10\n",
    "    avg_closeness[graph_name] = avg_value\n",
    "    max_closeness[graph_name] = max_value\n",
    "\n",
    "compute_closeness(niche_graph_nk, \"niche_graph\", niche_nodes_list)\n",
    "compute_closeness(almost_niche_graph_nk, \"almost_niche_graph\", almost_niche_nodes_list)\n",
    "# nb check networkx for closeness \n",
    "compute_closeness(mixed_graph_nk, \"mixed_graph\", mixed_nodes_list)\n",
    "\n",
    "avg_closeness_list = list(avg_closeness.values())\n",
    "max_closeness_list = list(max_closeness.values())\n",
    "\n",
    "centrality_df.loc[f\"Average closeness centrality\"] = avg_closeness_list\n",
    "centrality_df.loc[f\"Maximum closeness centrality\"] = max_closeness_list\n",
    "to_save = dict()\n",
    "\n",
    "to_save[\"niche_graph\"] = top10_closeness[\"niche_graph\"]\n",
    "to_save[\"almost_niche_graph\"] = top10_closeness[\"almost_niche_graph\"]\n",
    "to_save[\"mixed_graph\"] = top10_closeness[\"mixed_graph\"]\n",
    "folder_name = \"analysis_5\"\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "    print(f\"Created folder {folder_name}\")\n",
    "else:\n",
    "    print(f\"Folder {folder_name} already exists\")\n",
    "with open(\"analysis_5/closeness_centralities.json\", \"w\") as f:\n",
    "    json.dump(to_save,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14aa3de700b3c88a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:19:39.053004Z",
     "start_time": "2026-02-14T06:19:39.046840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Niche graph  Almost niche graph  Mixed graph\n",
      "Average betweenness centrality     0.004591            0.000092     0.000052\n",
      "Maximum betweenness centrality     0.086162            0.022253     0.008766\n",
      "Average IN-degree centrality       0.022803            0.001980     0.000353\n",
      "Maximum IN-degree centrality       0.002212            0.000000     0.000000\n",
      "Average OUT-degree centrality      0.022803            0.001980     0.000353\n",
      "Maximum OUT-degree centrality      0.002212            0.000000     0.000000\n",
      "Average closeness centrality       0.254731            0.181684     0.064286\n",
      "Maximum closeness centrality       0.517883            0.441322     0.186468\n"
     ]
    }
   ],
   "source": [
    "print(centrality_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882d5c9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:19:42.766791Z",
     "start_time": "2026-02-14T06:19:41.564774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Niche graph  Almost niche graph  \\\n",
      "Average pagerank centrality                0.002208            0.000067   \n",
      "Maximum pagerank centrality                0.024040            0.001011   \n",
      "Maximum normalized pagerank centrality    10.890214           15.054149   \n",
      "\n",
      "                                        Mixed graph  \n",
      "Average pagerank centrality                0.000065  \n",
      "Maximum pagerank centrality                0.003866  \n",
      "Maximum normalized pagerank centrality    59.320996  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "compute_centrality_nx(\"pagerank\", nx.pagerank, centrality_df)\n",
    "n_to_multiply = np.array([len(niche_nodes_list), len(almost_niche_nodes_list), len(mixed_nodes_list)])\n",
    "max_pr = centrality_df.loc[\"Maximum pagerank centrality\"].values\n",
    "processed_max_pr = list(max_pr*n_to_multiply)\n",
    "centrality_df.loc[\"Maximum normalized pagerank centrality\"] = processed_max_pr\n",
    "\n",
    "print(centrality_df)\n",
    "centrality_df.to_json(\"analysis_5/centrality.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b32130",
   "metadata": {},
   "source": [
    "### NETWORK STRUCTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8d60601",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:19:51.835459Z",
     "start_time": "2026-02-14T06:19:51.169943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strongly-connected components - continuous collaboration\n",
      "                        Niche graph  Almost niche graph  Mixed graph\n",
      "Biggest SCC size         350.000000         9043.000000  5507.000000\n",
      "Biggest SCC size ratio     0.772627            0.607239     0.358879\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"Strongly-connected components - continuous collaboration\")\n",
    "niche_scc_sets = list(nx.strongly_connected_components(niche_graph))\n",
    "niche_scc = len(max(niche_scc_sets, key=len))\n",
    "almost_niche_scc_sets = list(nx.strongly_connected_components(almost_niche_graph))\n",
    "almost_niche_scc = len(max(almost_niche_scc_sets, key=len))\n",
    "mixed_scc_sets = list(nx.strongly_connected_components(mixed_graph))\n",
    "mixed_scc = len(max(mixed_scc_sets, key=len))\n",
    "\n",
    "\n",
    "structure_df = pd.DataFrame({\"Niche graph\":niche_scc, \"Almost niche graph\":almost_niche_scc, \"Mixed graph\": mixed_scc}, index = [\"Biggest SCC size\"])\n",
    "structure_df.loc[\"Biggest SCC size ratio\"] = [niche_scc/len(niche_nodes_list), almost_niche_scc/len(almost_niche_nodes_list), mixed_scc/len(mixed_nodes_list)]\n",
    "\n",
    "print(structure_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f1ab937",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:19:53.685205Z",
     "start_time": "2026-02-14T06:19:53.321182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weakly-connected components - isolated 'families'\n",
      "                        Niche graph  Almost niche graph  Mixed graph\n",
      "Biggest SCC size         350.000000         9043.000000  5507.000000\n",
      "Biggest SCC size ratio     0.772627            0.607239     0.358879\n",
      "Biggest WCC size         452.000000        14141.000000  9979.000000\n",
      "Biggest WCC size ratio     0.997792            0.949570     0.650310\n"
     ]
    }
   ],
   "source": [
    "print(\"Weakly-connected components - isolated 'families'\")\n",
    "niche_wcc_sets = list(nx.weakly_connected_components(niche_graph))\n",
    "niche_wcc = len(max(niche_wcc_sets, key=len))\n",
    "almost_niche_wcc_sets = list(nx.weakly_connected_components(almost_niche_graph))\n",
    "almost_niche_wcc = len(max(almost_niche_wcc_sets, key=len))\n",
    "mixed_wcc_sets = list(nx.weakly_connected_components(mixed_graph))\n",
    "mixed_wcc = len(max(mixed_wcc_sets, key=len))\n",
    "\n",
    "structure_df.loc[\"Biggest WCC size\"] = [niche_wcc, almost_niche_wcc, mixed_wcc]\n",
    "structure_df.loc[\"Biggest WCC size ratio\"] = [niche_wcc/len(niche_nodes_list), almost_niche_wcc/len(almost_niche_nodes_list), mixed_wcc/len(mixed_nodes_list)]\n",
    "print(structure_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ddc4c5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:21:12.540612Z",
     "start_time": "2026-02-14T06:21:12.516960Z"
    }
   },
   "outputs": [],
   "source": [
    "niche_density =nx.density(niche_graph)\n",
    "almost_niche_density = nx.density(almost_niche_graph)\n",
    "mixed_density = nx.density(mixed_graph)\n",
    "structure_df.loc[\"Density\"] = [niche_density, almost_niche_density, mixed_density]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c86cc33b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:21:19.058792Z",
     "start_time": "2026-02-14T06:21:15.292059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reciprocity - became famous together\n"
     ]
    }
   ],
   "source": [
    "print(\"Reciprocity - became famous together\")\n",
    "niche_reciprocity = nx.reciprocity(niche_graph)\n",
    "almost_niche_reciprocity = nx.reciprocity(almost_niche_graph)\n",
    "mixed_reciprocity = nx.reciprocity(mixed_graph)\n",
    "structure_df.loc[\"Reciprocity\"] = [niche_reciprocity, almost_niche_reciprocity, mixed_reciprocity]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5724c387",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:21:28.477590Z",
     "start_time": "2026-02-14T06:21:20.988551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transitivity\n"
     ]
    }
   ],
   "source": [
    "print(\"Transitivity\")\n",
    "# Probabilità che se A ha lavorato con B e B con C, anche A abbia lavorato con C.\n",
    "niche_transitivity = nx.transitivity(niche_graph)\n",
    "almost_niche_transitivity = nx.transitivity(almost_niche_graph)\n",
    "mixed_transitivity = 0\n",
    "structure_df.loc[\"Transitivity\"] = [niche_transitivity, almost_niche_transitivity, mixed_transitivity]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae199cf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:21:50.005816Z",
     "start_time": "2026-02-14T06:21:28.531729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering\n"
     ]
    }
   ],
   "source": [
    "print(\"Clustering\")\n",
    "niche_clustering = nx.average_clustering(niche_graph)\n",
    "almost_niche_clustering = nx.average_clustering(almost_niche_graph)\n",
    "mixed_clustering = nx.bipartite.clustering(mixed_graph)\n",
    "structure_df.loc[\"Clustering\"] = [niche_clustering, almost_niche_clustering, mixed_clustering]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ba7edaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:21:56.390442Z",
     "start_time": "2026-02-14T06:21:56.385582Z"
    }
   },
   "outputs": [],
   "source": [
    "structure_df.to_json(\"analysis_5/structure.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd040cc",
   "metadata": {},
   "source": [
    "### ASSORTATIVITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8696935",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:22:00.462966Z",
     "start_time": "2026-02-14T06:21:59.467939Z"
    }
   },
   "outputs": [],
   "source": [
    "# degree assortativity\n",
    "import pandas as pd\n",
    "niche_degree_assort = nx.degree_assortativity_coefficient(niche_graph)\n",
    "almost_niche_degree_assort = nx.degree_assortativity_coefficient(almost_niche_graph)\n",
    "assortativity_df = pd.DataFrame({\"Niche graph\": niche_degree_assort, \"Almost niche graph\": almost_niche_degree_assort, \"Mixed graph\": None}, index = [\"Degree assortativity\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6efe9f75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:22:00.991782Z",
     "start_time": "2026-02-14T06:22:00.822477Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4176/2807361511.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  assortativity_df.loc[\"Attribute assortativity\"] = [None, None, mixed_attribute_assort]\n"
     ]
    }
   ],
   "source": [
    "# attribute assortativity\n",
    "import pandas as pd\n",
    "mixed_attribute_assort = nx.attribute_assortativity_coefficient(mixed_graph, \"status\")\n",
    "assortativity_df.loc[\"Attribute assortativity\"] = [None, None, mixed_attribute_assort]\n",
    "assortativity_df.to_json(\"analysis_5/assortativity.json\")\n",
    "mixed_mixing_matrix = nx.attribute_mixing_matrix(mixed_graph, \"status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ead90a9983ce83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:22:03.499978Z",
     "start_time": "2026-02-14T06:22:03.492442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                From almost-famous to famous actor  \\\n",
      "Collaborations                            0.365698   \n",
      "\n",
      "                From famous to almost-famous actor  \n",
      "Collaborations                            0.634302  \n"
     ]
    }
   ],
   "source": [
    "mixed_matrix_df = pd.DataFrame({\"From almost-famous to famous actor\": mixed_mixing_matrix[0,1], \"From famous to almost-famous actor\": mixed_mixing_matrix[1,0]}, index = [\"Collaborations\"])\n",
    "print(mixed_matrix_df)\n",
    "mixed_matrix_df.to_json(\"analysis_5/mixed_matrix.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28d4b5e9d8153dc",
   "metadata": {},
   "source": [
    "### DISTANCE METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ad5a0138966b4cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:22:05.685510Z",
     "start_time": "2026-02-14T06:22:05.674007Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import networkit as nk\n",
    "distance_df = pd.DataFrame(columns=[\"Niche graph\", \"Almost niche graph\", \"Mixed graph\"])\n",
    "diameter_list= list()\n",
    "avg_sp = list()\n",
    "def small_world_analysis(main_component, graph_name):\n",
    "    print(f\"Working on {graph_name}\")\n",
    "    main_component = nk.nxadapter.nx2nk(main_component)\n",
    "    print(\"Main component number of nodes:\", main_component.numberOfNodes())\n",
    "    print(\"Main component number of edges:\", main_component.numberOfEdges())\n",
    "    print(\"Analysing the diameter...\")\n",
    "    diameter = nk.distance.Diameter(main_component, algo=nk.distance.DiameterAlgo.EXACT)\n",
    "    diameter.run()\n",
    "    diameter_value = diameter.getDiameter()\n",
    "    print(\"Diameter:\", diameter_value[0])\n",
    "    diameter_list.append(diameter_value[0])\n",
    "    print(\"Computing the average path length (sampled)...\")\n",
    "    all_nodes = list(main_component.iterNodes())\n",
    "    sampled_nodes = all_nodes\n",
    "    batch_size = 200\n",
    "    num_batches = math.ceil(len(all_nodes) / batch_size)\n",
    "    total_distance_sum = 0\n",
    "    total_valid_pairs = 0\n",
    "    print(\"Number of batches:\", num_batches)\n",
    "    #for node in main_component.iterNodes():\n",
    "    for batch_iter in range(num_batches):\n",
    "        start_idx = batch_iter * batch_size\n",
    "        end_idx = min((batch_iter + 1) * batch_size, len(all_nodes))\n",
    "        batch_nodes = sampled_nodes[start_idx:end_idx]\n",
    "\n",
    "        spsp = nk.distance.SPSP(main_component, batch_nodes)\n",
    "        spsp.run()\n",
    "        distances_from_source = spsp.getDistances()\n",
    "\n",
    "        distances_array = np.array(distances_from_source)\n",
    "        valid_mask = distances_array > 0\n",
    "        total_distance_sum += distances_array[valid_mask].sum()\n",
    "        total_valid_pairs += valid_mask.sum()\n",
    "\n",
    "        del spsp\n",
    "        del distances_array\n",
    "        if batch_iter % 10 == 0 and batch_iter != 0:\n",
    "            print(\"Finished batch:\", batch_iter)\n",
    "\n",
    "    avg_path_length = total_distance_sum / total_valid_pairs\n",
    "    print(\"Average sampled path length:\", avg_path_length)\n",
    "    avg_sp.append(avg_path_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a01dff3256a5c3c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:22:15.689434Z",
     "start_time": "2026-02-14T06:22:09.473577Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "niche_main_cc = max(nx.weakly_connected_components(niche_graph), key = len)\n",
    "niche_main_cc = niche_graph.subgraph(niche_main_cc).copy()\n",
    "niche_main_cc = niche_main_cc.to_undirected()\n",
    "almost_niche_main_cc = max(nx.weakly_connected_components(almost_niche_graph), key = len)\n",
    "almost_niche_main_cc = almost_niche_graph.subgraph(almost_niche_main_cc).copy()\n",
    "almost_niche_main_cc = almost_niche_main_cc.to_undirected()\n",
    "mixed_main_cc = max(nx.weakly_connected_components(mixed_graph), key = len)\n",
    "mixed_main_cc = mixed_graph.subgraph(mixed_main_cc).copy()\n",
    "mixed_main_cc = mixed_main_cc.to_undirected()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "241dec0c3b543e56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:22:45.557207Z",
     "start_time": "2026-02-14T06:22:16.717041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on niche main component\n",
      "Main component number of nodes: 452\n",
      "Main component number of edges: 3932\n",
      "Analysing the diameter...\n",
      "Diameter: 5\n",
      "Computing the average path length (sampled)...\n",
      "Number of batches: 3\n",
      "Average sampled path length: 2.563840433255499\n",
      "Working on almost_niche main component\n",
      "Main component number of nodes: 14141\n",
      "Main component number of edges: 346990\n",
      "Analysing the diameter...\n",
      "Diameter: 9\n",
      "Computing the average path length (sampled)...\n",
      "Number of batches: 71\n",
      "Finished batch: 10\n",
      "Finished batch: 20\n",
      "Finished batch: 30\n",
      "Finished batch: 40\n",
      "Finished batch: 50\n",
      "Finished batch: 60\n",
      "Finished batch: 70\n",
      "Average sampled path length: 3.0984554227392795\n",
      "Working on mixed main component\n",
      "Main component number of nodes: 9979\n",
      "Main component number of edges: 69565\n",
      "Analysing the diameter...\n",
      "Diameter: 6\n",
      "Computing the average path length (sampled)...\n",
      "Number of batches: 50\n",
      "Finished batch: 10\n",
      "Finished batch: 20\n",
      "Finished batch: 30\n",
      "Finished batch: 40\n",
      "Average sampled path length: 3.7540411131164584\n"
     ]
    }
   ],
   "source": [
    "small_world_analysis(niche_main_cc, \"niche main component\")\n",
    "small_world_analysis(almost_niche_main_cc, \"almost_niche main component\")\n",
    "small_world_analysis(mixed_main_cc, \"mixed main component\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9302a67f36d0278",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:22:45.635536Z",
     "start_time": "2026-02-14T06:22:45.631579Z"
    }
   },
   "outputs": [],
   "source": [
    "distance_df.loc[\"Diameter\"] = diameter_list\n",
    "distance_df.loc[\"Main connected component shortest path\"] = avg_sp\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3237c4edc9f98f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T06:22:56.532531Z",
     "start_time": "2026-02-14T06:22:56.298219Z"
    }
   },
   "outputs": [],
   "source": [
    "distance_df.loc[\"Graph - number of nodes\"] = [len(list(niche_graph.nodes())), len(list(almost_niche_graph.nodes())), len(list(mixed_graph.nodes()))]\n",
    "distance_df.loc[\"Graph - number of edges\"] = [len(list(niche_graph.edges())), len(list(almost_niche_graph.edges())), len(list(mixed_graph.edges()))]\n",
    "distance_df.loc[\"Number of connected components\"] = [len(niche_wcc_sets), len(almost_niche_wcc_sets), len(mixed_wcc_sets)]\n",
    "distance_df.to_json(\"analysis_5/distance.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_mining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
