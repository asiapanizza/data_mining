{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1ef718b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T22:16:29.074604Z",
     "start_time": "2026-02-08T22:16:27.869901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                cast  \\\n",
      "0  [{'cast_id': 14, 'character': 'Woody (voice)',...   \n",
      "1  [{'cast_id': 1, 'character': 'Alan Parrish', '...   \n",
      "2  [{'cast_id': 2, 'character': 'Max Goldman', 'c...   \n",
      "3  [{'cast_id': 1, 'character': \"Savannah 'Vannah...   \n",
      "4  [{'cast_id': 1, 'character': 'George Banks', '...   \n",
      "\n",
      "                                                crew     id  \n",
      "0  [{'credit_id': '52fe4284c3a36847f8024f49', 'de...    862  \n",
      "1  [{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...   8844  \n",
      "2  [{'credit_id': '52fe466a9251416c75077a89', 'de...  15602  \n",
      "3  [{'credit_id': '52fe44779251416c91011acb', 'de...  31357  \n",
      "4  [{'credit_id': '52fe44959251416c75039ed7', 'de...  11862  \n",
      "Index(['cast', 'crew', 'id'], dtype='str')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "creds = pd.read_csv(\"datasets/credits.csv\")\n",
    "print(creds.head())\n",
    "print(creds.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7359ff4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:1067\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._convert_tokens\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:1177\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:1837\u001b[39m, in \u001b[36mpandas._libs.parsers._try_int64\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Number is not int",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ratings = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdatasets/ratings.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(ratings.head())\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(ratings.columns)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Asia.LAPTOP-ASIA\\miniconda3\\envs\\data_mining\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:873\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, skip_blank_lines, parse_dates, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m    861\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m    862\u001b[39m     dialect,\n\u001b[32m    863\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    869\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m    870\u001b[39m )\n\u001b[32m    871\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Asia.LAPTOP-ASIA\\miniconda3\\envs\\data_mining\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:306\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Asia.LAPTOP-ASIA\\miniconda3\\envs\\data_mining\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1947\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1940\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1941\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1942\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1943\u001b[39m     (\n\u001b[32m   1944\u001b[39m         index,\n\u001b[32m   1945\u001b[39m         columns,\n\u001b[32m   1946\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1947\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1948\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1949\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1950\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1951\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Asia.LAPTOP-ASIA\\miniconda3\\envs\\data_mining\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:215\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    217\u001b[39m         data = _concatenate_chunks(chunks, \u001b[38;5;28mself\u001b[39m.names)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:832\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:911\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:1009\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._convert_column_data\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:1070\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._convert_tokens\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv(\"datasets/ratings.csv\")\n",
    "print(ratings.head())\n",
    "print(ratings.columns)\n",
    "print(len(ratings))\n",
    "movie_ids = []\n",
    "avg_ratings = []\n",
    "for movieid, group in ratings.groupby([\"movieId\"]):\n",
    "    movie_ids.append(str(movieid[0]))\n",
    "    avg_ratings.append(group[\"rating\"].mean())\n",
    "\n",
    "clean_ratings = pd.DataFrame({\"id\" : movie_ids, \"avg_rating\": avg_ratings})\n",
    "print(clean_ratings.head())\n",
    "print(len(clean_ratings))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "027a5e1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T22:16:30.187046Z",
     "start_time": "2026-02-08T22:16:29.656986Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asia.LAPTOP-ASIA\\AppData\\Local\\Temp\\ipykernel_3224\\1810640024.py:1: DtypeWarning: Columns (0: popularity) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies_meta = pd.read_csv(\"datasets/movies_metadata.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   adult                              belongs_to_collection    budget  \\\n",
      "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
      "1  False                                                NaN  65000000   \n",
      "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
      "3  False                                                NaN  16000000   \n",
      "4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
      "\n",
      "                                              genres  \\\n",
      "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
      "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
      "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
      "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
      "4                     [{'id': 35, 'name': 'Comedy'}]   \n",
      "\n",
      "                               homepage     id    imdb_id original_language  \\\n",
      "0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n",
      "1                                   NaN   8844  tt0113497                en   \n",
      "2                                   NaN  15602  tt0113228                en   \n",
      "3                                   NaN  31357  tt0114885                en   \n",
      "4                                   NaN  11862  tt0113041                en   \n",
      "\n",
      "                original_title  \\\n",
      "0                    Toy Story   \n",
      "1                      Jumanji   \n",
      "2             Grumpier Old Men   \n",
      "3            Waiting to Exhale   \n",
      "4  Father of the Bride Part II   \n",
      "\n",
      "                                            overview  ... release_date  \\\n",
      "0  Led by Woody, Andy's toys live happily in his ...  ...   1995-10-30   \n",
      "1  When siblings Judy and Peter discover an encha...  ...   1995-12-15   \n",
      "2  A family wedding reignites the ancient feud be...  ...   1995-12-22   \n",
      "3  Cheated on, mistreated and stepped on, the wom...  ...   1995-12-22   \n",
      "4  Just when George Banks has recovered from his ...  ...   1995-02-10   \n",
      "\n",
      "       revenue runtime                                   spoken_languages  \\\n",
      "0  373554033.0    81.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
      "1  262797249.0   104.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
      "2          0.0   101.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
      "3   81452156.0   127.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
      "4   76578911.0   106.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
      "\n",
      "     status                                            tagline  \\\n",
      "0  Released                                                NaN   \n",
      "1  Released          Roll the dice and unleash the excitement!   \n",
      "2  Released  Still Yelling. Still Fighting. Still Ready for...   \n",
      "3  Released  Friends are the people who let you be yourself...   \n",
      "4  Released  Just When His World Is Back To Normal... He's ...   \n",
      "\n",
      "                         title  video vote_average vote_count  \n",
      "0                    Toy Story  False          7.7     5415.0  \n",
      "1                      Jumanji  False          6.9     2413.0  \n",
      "2             Grumpier Old Men  False          6.5       92.0  \n",
      "3            Waiting to Exhale  False          6.1       34.0  \n",
      "4  Father of the Bride Part II  False          5.7      173.0  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "Index(['adult', 'belongs_to_collection', 'budget', 'genres', 'homepage', 'id',\n",
      "       'imdb_id', 'original_language', 'original_title', 'overview',\n",
      "       'popularity', 'poster_path', 'production_companies',\n",
      "       'production_countries', 'release_date', 'revenue', 'runtime',\n",
      "       'spoken_languages', 'status', 'tagline', 'title', 'video',\n",
      "       'vote_average', 'vote_count'],\n",
      "      dtype='str')\n",
      "0        [{'iso_3166_1': 'US', 'name': 'United States o...\n",
      "1        [{'iso_3166_1': 'US', 'name': 'United States o...\n",
      "2        [{'iso_3166_1': 'US', 'name': 'United States o...\n",
      "3        [{'iso_3166_1': 'US', 'name': 'United States o...\n",
      "4        [{'iso_3166_1': 'US', 'name': 'United States o...\n",
      "                               ...                        \n",
      "45461               [{'iso_3166_1': 'IR', 'name': 'Iran'}]\n",
      "45462        [{'iso_3166_1': 'PH', 'name': 'Philippines'}]\n",
      "45463    [{'iso_3166_1': 'US', 'name': 'United States o...\n",
      "45464             [{'iso_3166_1': 'RU', 'name': 'Russia'}]\n",
      "45465     [{'iso_3166_1': 'GB', 'name': 'United Kingdom'}]\n",
      "Name: production_countries, Length: 45466, dtype: str\n",
      "0        1995-10-30\n",
      "1        1995-12-15\n",
      "2        1995-12-22\n",
      "3        1995-12-22\n",
      "4        1995-02-10\n",
      "            ...    \n",
      "45461           NaN\n",
      "45462    2011-11-17\n",
      "45463    2003-08-01\n",
      "45464    1917-10-21\n",
      "45465    2017-06-09\n",
      "Name: release_date, Length: 45466, dtype: str\n",
      "CLEAN DF\n",
      "   adult                              belongs_to_collection    budget  \\\n",
      "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
      "1  False                                                     65000000   \n",
      "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
      "3  False                                                     16000000   \n",
      "4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
      "\n",
      "                                              genres  \\\n",
      "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
      "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
      "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
      "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
      "4                     [{'id': 35, 'name': 'Comedy'}]   \n",
      "\n",
      "                               homepage     id    imdb_id original_language  \\\n",
      "0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n",
      "1                                         8844  tt0113497                en   \n",
      "2                                        15602  tt0113228                en   \n",
      "3                                        31357  tt0114885                en   \n",
      "4                                        11862  tt0113041                en   \n",
      "\n",
      "                original_title  \\\n",
      "0                    Toy Story   \n",
      "1                      Jumanji   \n",
      "2             Grumpier Old Men   \n",
      "3            Waiting to Exhale   \n",
      "4  Father of the Bride Part II   \n",
      "\n",
      "                                            overview  ... release_date  \\\n",
      "0  Led by Woody, Andy's toys live happily in his ...  ...   1995-10-30   \n",
      "1  When siblings Judy and Peter discover an encha...  ...   1995-12-15   \n",
      "2  A family wedding reignites the ancient feud be...  ...   1995-12-22   \n",
      "3  Cheated on, mistreated and stepped on, the wom...  ...   1995-12-22   \n",
      "4  Just when George Banks has recovered from his ...  ...   1995-02-10   \n",
      "\n",
      "       revenue runtime                                   spoken_languages  \\\n",
      "0  373554033.0    81.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
      "1  262797249.0   104.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
      "2          0.0   101.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
      "3   81452156.0   127.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
      "4   76578911.0   106.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
      "\n",
      "     status                                            tagline  \\\n",
      "0  Released                                                      \n",
      "1  Released          Roll the dice and unleash the excitement!   \n",
      "2  Released  Still Yelling. Still Fighting. Still Ready for...   \n",
      "3  Released  Friends are the people who let you be yourself...   \n",
      "4  Released  Just When His World Is Back To Normal... He's ...   \n",
      "\n",
      "                         title  video vote_average vote_count  \n",
      "0                    Toy Story  False          7.7     5415.0  \n",
      "1                      Jumanji  False          6.9     2413.0  \n",
      "2             Grumpier Old Men  False          6.5       92.0  \n",
      "3            Waiting to Exhale  False          6.1       34.0  \n",
      "4  Father of the Bride Part II  False          5.7      173.0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "movies_meta = pd.read_csv(\"datasets/movies_metadata.csv\")\n",
    "print(movies_meta.head())\n",
    "print(movies_meta.columns)\n",
    "print(movies_meta[\"production_countries\"])\n",
    "print(movies_meta[\"release_date\"])\n",
    "movies_meta = movies_meta.fillna(\"\")\n",
    "print(\"CLEAN DF\")\n",
    "print(movies_meta.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "13fcacb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching complete historical series from MeasuringWorth...\n",
      "Success! File saved as 'purchasing_power_1874_2020.csv'\n",
      "     Year     CPI  PP_2020_Dollar\n",
      "143  2016  240.01          1.0783\n",
      "144  2017  245.12          1.0559\n",
      "145  2018  251.11          1.0307\n",
      "146  2019  255.66          1.0123\n",
      "147  2020  258.81          1.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- UNIFIED EXTRACTION: 1874 to 202 from Measuring Worth ---\n",
    "print(\"Fetching complete historical series from MeasuringWorth...\")\n",
    "\n",
    "# We adjust the URL parameters to cover the full range\n",
    "url_complete = \"https://www.measuringworth.com/datasets/uscpi/result.php?year_source=1874&year_result=2020\"\n",
    "\n",
    "try:\n",
    "    # 1. Read the tables from the URL\n",
    "    tables = pd.read_html(url_complete)\n",
    "    \n",
    "    # 2. Select the data table (usually the second one)\n",
    "    df = tables[1].copy()\n",
    "    \n",
    "    # 3. Name the columns\n",
    "    df.columns = ['Year', 'CPI']\n",
    "    \n",
    "    # 4. Clean the data (Handle the footer notes and headers)\n",
    "    # Convert to numeric, turning text notes into NaN\n",
    "    df['Year'] = pd.to_numeric(df['Year'], errors='coerce')\n",
    "    df['CPI'] = pd.to_numeric(df['CPI'], errors='coerce')\n",
    "    \n",
    "    # Drop rows that are not numbers (like the \"Average 1982-84\" note)\n",
    "    df = df.dropna(subset=['Year', 'CPI'])\n",
    "    \n",
    "    # 5. Final Formatting\n",
    "    df['Year'] = df['Year'].astype(int)\n",
    "    \n",
    "    # 6. Calculate Purchasing Power relative to 2020\n",
    "    # Formula: (CPI in 2017 / CPI in Year X)\n",
    "    cpi_2020 = df.loc[df['Year'] == 2020, 'CPI'].values[0]\n",
    "    df['PP_2020_Dollar'] = (cpi_2020 / df['CPI']).round(4)\n",
    "    \n",
    "    # 7. Save to CSV\n",
    "    df.to_csv(\"purchasing_power_1874_2020.csv\", index=False)\n",
    "    \n",
    "    print(\"Success! File saved as 'purchasing_power_1874_2020.csv'\")\n",
    "    print(df.tail()) # Shows the most recent years (2013-2020)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6ec37ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         title     id  \\\n",
      "0                    Toy Story    862   \n",
      "1                      Jumanji   8844   \n",
      "2             Grumpier Old Men  15602   \n",
      "3            Waiting to Exhale  31357   \n",
      "4  Father of the Bride Part II  11862   \n",
      "\n",
      "                                              genres original_language  \\\n",
      "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...                en   \n",
      "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...                en   \n",
      "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...                en   \n",
      "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...                en   \n",
      "4                     [{'id': 35, 'name': 'Comedy'}]                en   \n",
      "\n",
      "  release_date                               production_countries  \\\n",
      "0   1995-10-30  [{'iso_3166_1': 'US', 'name': 'United States o...   \n",
      "1   1995-12-15  [{'iso_3166_1': 'US', 'name': 'United States o...   \n",
      "2   1995-12-22  [{'iso_3166_1': 'US', 'name': 'United States o...   \n",
      "3   1995-12-22  [{'iso_3166_1': 'US', 'name': 'United States o...   \n",
      "4   1995-02-10  [{'iso_3166_1': 'US', 'name': 'United States o...   \n",
      "\n",
      "       revenue                                               cast  \n",
      "0  373554033.0  [{'cast_id': 14, 'character': 'Woody (voice)',...  \n",
      "1  262797249.0  [{'cast_id': 1, 'character': 'Alan Parrish', '...  \n",
      "2          0.0  [{'cast_id': 2, 'character': 'Max Goldman', 'c...  \n",
      "3   81452156.0  [{'cast_id': 1, 'character': \"Savannah 'Vannah...  \n",
      "4   76578911.0  [{'cast_id': 1, 'character': 'George Banks', '...  \n",
      "Index(['title', 'id', 'genres', 'original_language', 'release_date',\n",
      "       'production_countries', 'revenue', 'cast'],\n",
      "      dtype='str')\n",
      "title                                                           Toy Story\n",
      "id                                                                    862\n",
      "genres                  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...\n",
      "original_language                                                      en\n",
      "release_date                                                   1995-10-30\n",
      "production_countries    [{'iso_3166_1': 'US', 'name': 'United States o...\n",
      "revenue                                                       373554033.0\n",
      "cast                    [{'cast_id': 14, 'character': 'Woody (voice)',...\n",
      "Name: 0, dtype: object\n",
      "[{'cast_id': 14, 'character': 'Woody (voice)', 'credit_id': '52fe4284c3a36847f8024f95', 'gender': 2, 'id': 31, 'name': 'Tom Hanks', 'order': 0, 'profile_path': '/pQFoyx7rp09CJTAb932F2g8Nlho.jpg'}, {'cast_id': 15, 'character': 'Buzz Lightyear (voice)', 'credit_id': '52fe4284c3a36847f8024f99', 'gender': 2, 'id': 12898, 'name': 'Tim Allen', 'order': 1, 'profile_path': '/uX2xVf6pMmPepxnvFWyBtjexzgY.jpg'}, {'cast_id': 16, 'character': 'Mr. Potato Head (voice)', 'credit_id': '52fe4284c3a36847f8024f9d', 'gender': 2, 'id': 7167, 'name': 'Don Rickles', 'order': 2, 'profile_path': '/h5BcaDMPRVLHLDzbQavec4xfSdt.jpg'}, {'cast_id': 17, 'character': 'Slinky Dog (voice)', 'credit_id': '52fe4284c3a36847f8024fa1', 'gender': 2, 'id': 12899, 'name': 'Jim Varney', 'order': 3, 'profile_path': '/eIo2jVVXYgjDtaHoF19Ll9vtW7h.jpg'}, {'cast_id': 18, 'character': 'Rex (voice)', 'credit_id': '52fe4284c3a36847f8024fa5', 'gender': 2, 'id': 12900, 'name': 'Wallace Shawn', 'order': 4, 'profile_path': '/oGE6JqPP2xH4tNORKNqxbNPYi7u.jpg'}, {'cast_id': 19, 'character': 'Hamm (voice)', 'credit_id': '52fe4284c3a36847f8024fa9', 'gender': 2, 'id': 7907, 'name': 'John Ratzenberger', 'order': 5, 'profile_path': '/yGechiKWL6TJDfVE2KPSJYqdMsY.jpg'}, {'cast_id': 20, 'character': 'Bo Peep (voice)', 'credit_id': '52fe4284c3a36847f8024fad', 'gender': 1, 'id': 8873, 'name': 'Annie Potts', 'order': 6, 'profile_path': '/eryXT84RL41jHSJcMy4kS3u9y6w.jpg'}, {'cast_id': 26, 'character': 'Andy (voice)', 'credit_id': '52fe4284c3a36847f8024fc1', 'gender': 0, 'id': 1116442, 'name': 'John Morris', 'order': 7, 'profile_path': '/vYGyvK4LzeaUCoNSHtsuqJUY15M.jpg'}, {'cast_id': 22, 'character': 'Sid (voice)', 'credit_id': '52fe4284c3a36847f8024fb1', 'gender': 2, 'id': 12901, 'name': 'Erik von Detten', 'order': 8, 'profile_path': '/twnF1ZaJ1FUNUuo6xLXwcxjayBE.jpg'}, {'cast_id': 23, 'character': 'Mrs. Davis (voice)', 'credit_id': '52fe4284c3a36847f8024fb5', 'gender': 1, 'id': 12133, 'name': 'Laurie Metcalf', 'order': 9, 'profile_path': '/unMMIT60eoBM2sN2nyR7EZ2BvvD.jpg'}, {'cast_id': 24, 'character': 'Sergeant (voice)', 'credit_id': '52fe4284c3a36847f8024fb9', 'gender': 2, 'id': 8655, 'name': 'R. Lee Ermey', 'order': 10, 'profile_path': '/r8GBqFBjypLUP9VVqDqfZ7wYbSs.jpg'}, {'cast_id': 25, 'character': 'Hannah (voice)', 'credit_id': '52fe4284c3a36847f8024fbd', 'gender': 1, 'id': 12903, 'name': 'Sarah Freeman', 'order': 11, 'profile_path': None}, {'cast_id': 27, 'character': 'TV Announcer (voice)', 'credit_id': '52fe4284c3a36847f8024fc5', 'gender': 2, 'id': 37221, 'name': 'Penn Jillette', 'order': 12, 'profile_path': '/zmAaXUdx12NRsssgHbk1T31j2x9.jpg'}]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "import ast\n",
    "graph = nx.Graph()\n",
    "creds[\"id\"] = creds[\"id\"].astype(str)\n",
    "work_df = pd.merge(movies_meta[[\"title\", \"id\", \"genres\", \"original_language\", \"release_date\", \"production_countries\", \"revenue\"]], creds[[\"cast\", \"id\"]], on= \"id\", how =\"inner\")\n",
    "#work_df = pd.merge(work_df, clean_ratings, on= \"id\", how =\"left\")\n",
    "print(work_df.head())\n",
    "print(work_df.columns)\n",
    "print(work_df.iloc[0])\n",
    "print(work_df[\"cast\"].iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38f2cd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1874\n",
      "2020\n"
     ]
    }
   ],
   "source": [
    "all_dates = []\n",
    "for date in work_df[\"release_date\"]:\n",
    "    date = date[:4]\n",
    "    if date != \"\":\n",
    "        all_dates.append(int(date))\n",
    "\n",
    "print(min(all_dates))\n",
    "print(max(all_dates))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a2740462",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T22:16:50.346619Z",
     "start_time": "2026-02-08T22:16:30.784318Z"
    }
   },
   "outputs": [],
   "source": [
    "titles = work_df[\"title\"].tolist()\n",
    "genres = work_df[\"genres\"].tolist()\n",
    "languages = work_df[\"original_language\"].tolist()\n",
    "dates = work_df[\"release_date\"].tolist()\n",
    "countries = work_df[\"production_countries\"].tolist()\n",
    "cast = work_df[\"cast\"].tolist()\n",
    "#ratings = work_df[\"avg_rating\"].tolist()\n",
    "revenue = work_df[\"revenue\"].tolist()\n",
    "tupled_movie = zip(titles, genres, languages, dates, countries, revenue, cast)\n",
    "edges = []\n",
    "actors = []\n",
    "movies = []\n",
    "for el in list(tupled_movie):\n",
    "    genres = ast.literal_eval(el[1])\n",
    "    genres = [genre[\"name\"] for genre in genres]\n",
    "    if el[4] != \"\" and isinstance(el[4], str):\n",
    "        try:\n",
    "            countries = ast.literal_eval(el[4])\n",
    "        except (ValueError, SyntaxError):\n",
    "            countries = []\n",
    "    else:\n",
    "        countries = []\n",
    "    clean_country = []\n",
    "    if isinstance(countries,list) and len(countries) > 0:  \n",
    "        for country in countries:\n",
    "            if country[\"name\"]:\n",
    "                clean_country.append(country[\"name\"])\n",
    "    year = el[3]\n",
    "    if year[:4].isdigit():\n",
    "        year = int(year[:4])\n",
    "        if el[-2]!= \"\" and not el[-2] is None and el[-2]!=[]:\n",
    "            try:\n",
    "                revenue = el[-2]/df[df[\"Year\"] == year][\"PP_2020_Dollar\"].astype(float).values\n",
    "                revenue = revenue.tolist()[0]\n",
    "            except IndexError as e:\n",
    "                print(el[-2])\n",
    "                print(year)\n",
    "    else:\n",
    "        revenue = None\n",
    "    movie_attributes = {\"genres\": genres, \"countries\": clean_country, \"language\": el[2], \"revenue_2020_$\" : revenue, \"release_date\": year}\n",
    "    el_list = ast.literal_eval(el[-1])\n",
    "    if len(el_list) >0:\n",
    "        movie_attributes[\"led_by_man\"] = True if el_list[0][\"gender\"]== 2 else False\n",
    "    else:\n",
    "        movie_attributes[\"led_by_man\"] = None\n",
    "    movies.append((\"movie: \"+ str(el[0]), movie_attributes))\n",
    "    for actor in el_list:\n",
    "        gender = \"male\" if actor[\"gender\"] == 2 else \"female\"\n",
    "        edge_attributes = {\"character\" : actor[\"character\"]}\n",
    "        if len(clean_country) > 0 and clean_country != None:\n",
    "            clean_country = clean_country\n",
    "        else:\n",
    "            clean_country = []\n",
    "        actor_attributes = {\"gender\": gender, \"countries\" : clean_country, \"year\":year, \"genres\":genres, \"revenue_2020_$\" : revenue}\n",
    "        actors.append((\"actor: \"+ actor[\"name\"], actor_attributes))\n",
    "        edges.append((\"movie: \"+ str(el[0]), \"actor: \"+ actor[\"name\"], edge_attributes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d37f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('movie: Toy Story', {'genres': ['Animation', 'Comedy', 'Family'], 'countries': ['United States of America'], 'language': 'en', 'revenue_2017_$': array([2.32251948e+08]), 'release_date': 1995, 'led_by_man': True})\n"
     ]
    }
   ],
   "source": [
    "print(movies[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c7165be4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T22:16:52.890202Z",
     "start_time": "2026-02-08T22:16:50.820220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45538\n",
      "563112\n",
      "563112\n",
      "('actor: Tom Hanks', {'gender': 'male', 'countries': ['United States of America'], 'year': 1995, 'genres': ['Animation', 'Comedy', 'Family'], 'revenue_2020_$': 219970576.49275705})\n",
      "Unique actors found: 202747\n",
      "('actor: Tom Hanks', {'gender': 'male', 'countries': ['Hong Kong', 'Australia', 'United Kingdom', 'Mexico', 'Hungary', 'France', 'Italy', 'United States of America', 'Singapore', 'Germany', 'India', 'Malta'], 'avg_movie_revenue_2020_$': 97984814, 'genre': 'Comedy', 'all_genres': ['Comedy', 'Drama', 'Documentary', 'Family', 'Animation', 'Thriller', 'Romance', 'History', 'Fantasy', 'Crime', 'Action', 'War', 'Adventure', 'Science Fiction', 'Horror', 'Mystery', 'Foreign', 'TV Movie'], 'period': 'new_hollywood'})\n"
     ]
    }
   ],
   "source": [
    "print(len(movies))\n",
    "print(len(actors)) \n",
    "print(len(edges))\n",
    "print(actors[0])\n",
    "# I want there to be a unique node for each actor\n",
    "clean_actors_dict = {}\n",
    "\n",
    "\n",
    "for name, attrs in actors:\n",
    "    if name not in clean_actors_dict:\n",
    "        new_attrs = attrs.copy()\n",
    "        new_attrs[\"countries\"] = set(attrs.get(\"countries\") or [])\n",
    "        genres = attrs.get(\"genres\") or []\n",
    "        genre_dict = dict()\n",
    "        for genre in genres:\n",
    "            genre_dict[genre] = 1\n",
    "        new_attrs[\"genres\"] = genre_dict\n",
    "        year = attrs.get(\"year\") or 0\n",
    "        year_dict = dict()\n",
    "        year_dict[\"old_hollywood\"] = 0\n",
    "        year_dict[\"new_hollywood\"] = 0\n",
    "        if year> 0 and year< 1967:\n",
    "            year_dict[\"old_hollywood\"] +=1\n",
    "        elif year >= 1967:\n",
    "            year_dict[\"new_hollywood\"] +=1\n",
    "        new_attrs[\"year\"] = year_dict\n",
    "        #new_attrs[\"avg_movie_rating\"] = [attrs[\"avg_movie_rating\"]]\n",
    "        if not attrs[\"revenue_2020_$\"] is None:\n",
    "            new_attrs[\"avg_movie_revenue_2020_$\"] = [int(attrs[\"revenue_2020_$\"])]\n",
    "        else:\n",
    "            new_attrs[\"avg_movie_revenue_2020_$\"] = []\n",
    "        clean_actors_dict[name] = new_attrs\n",
    "    else:   \n",
    "        extra_countries = set(attrs.get(\"countries\") or [])\n",
    "        clean_actors_dict[name][\"countries\"].update(extra_countries)\n",
    "        extra_genres = attrs.get(\"genres\") or []\n",
    "        for genre in extra_genres:\n",
    "            if genre not in clean_actors_dict[name][\"genres\"]:\n",
    "                clean_actors_dict[name][\"genres\"][genre] = 1\n",
    "            else: \n",
    "                clean_actors_dict[name][\"genres\"][genre] +=1\n",
    "        current_year = attrs[\"year\"] or 0\n",
    "        if current_year> 0 and current_year< 1967:\n",
    "            clean_actors_dict[name][\"year\"][\"old_hollywood\"] +=1\n",
    "        elif current_year >= 1967:\n",
    "            clean_actors_dict[name][\"year\"][\"new_hollywood\"] +=1\n",
    "        #clean_actors_dict[name][\"avg_movie_rating\"].append(attrs[\"avg_movie_rating\"])\n",
    "        if not attrs[\"revenue_2020_$\"] is None:\n",
    "            clean_actors_dict[name][\"avg_movie_revenue_2020_$\"].append(int(attrs[\"revenue_2020_$\"]))\n",
    "\n",
    "final_actors = []\n",
    "\n",
    "for name, attrs in clean_actors_dict.items():\n",
    "    attrs[\"countries\"] = list(attrs[\"countries\"])\n",
    "    genres = list(attrs[\"genres\"].items())\n",
    "    sorted_genres = sorted(genres, key=lambda x: x[1], reverse = True)\n",
    "    if len(sorted_genres)> 0:\n",
    "        attrs[\"genre\"] = sorted_genres[0][0]\n",
    "    else:\n",
    "        attrs[\"genre\"] = \"\"\n",
    "    attrs[\"all_genres\"] = [name for name, _ in sorted_genres]\n",
    "    periods = list(attrs[\"year\"].items())\n",
    "    del attrs[\"genres\"]\n",
    "    sorted_periods = sorted(periods, key=lambda x: x[1], reverse = True)\n",
    "    attrs[\"period\"] = sorted_periods[0][0]\n",
    "    del attrs[\"year\"]\n",
    "    #attrs[\"avg_movie_rating\"] = sum(attrs[\"avg_movie_rating\"]) /len(attrs[\"avg_movie_rating\"])\n",
    "    if len(attrs[\"avg_movie_revenue_2020_$\"]) != 0:\n",
    "        attrs[\"avg_movie_revenue_2020_$\"] = int(sum(attrs[\"avg_movie_revenue_2020_$\"])/ len(attrs[\"avg_movie_revenue_2020_$\"]))\n",
    "    else:\n",
    "        attrs[\"avg_movie_revenue_2020_$\"] = 0\n",
    "    del attrs[\"revenue_2020_$\"]\n",
    "    final_actors.append((name, attrs))\n",
    "\n",
    "print(f\"Unique actors found: {len(final_actors)}\")\n",
    "print(final_actors[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7c3c6361",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T22:16:57.335570Z",
     "start_time": "2026-02-08T22:16:53.934508Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx \n",
    "graph = nx.Graph()\n",
    "for movie, diz in movies:\n",
    "    graph.add_node(movie, **diz, bipartite = 0)\n",
    "for actor, diz in final_actors:\n",
    "    if not isinstance(diz[\"genre\"], str):\n",
    "        print(diz)\n",
    "    graph.add_node(actor, **diz, bipartite = 1)\n",
    "for edge1, edge2, diz in edges:\n",
    "    graph.add_edge(edge1, edge2, **diz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "71b534db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T22:16:58.028804Z",
     "start_time": "2026-02-08T22:16:57.934280Z"
    }
   },
   "outputs": [],
   "source": [
    "movie_nodes = {n for n, d in graph.nodes(data=True) if d[\"bipartite\"] == 0}\n",
    "actor_nodes = {n for n, d in graph.nodes(data=True) if d[\"bipartite\"] == 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "017670f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T22:17:08.512986Z",
     "start_time": "2026-02-08T22:17:04.243391Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "to_dump = nx.readwrite.json_graph.node_link_data(graph)\n",
    "with open(\"full_graph.json\", \"w\") as f:\n",
    "    json.dump(to_dump, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ac72a5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T22:17:12.601410Z",
     "start_time": "2026-02-08T22:17:09.405624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21182\n",
      "111458\n",
      "330284\n"
     ]
    }
   ],
   "source": [
    "# let's create a graph only for the movies produced in Hollywood (movies produced by the US, with co-production with other countries allowed)\n",
    "hollywood_graph = nx.Graph()\n",
    "\n",
    "movie_counter = 0\n",
    "for movie, diz in movies:\n",
    "    if \"United States of America\" in diz[\"countries\"]:\n",
    "        movie_counter += 1\n",
    "        hollywood_graph.add_node(movie, **diz, bipartite = 0)\n",
    "print(movie_counter)\n",
    "actor_counter = 0\n",
    "for actor, diz in final_actors:\n",
    "    if \"United States of America\" in diz[\"countries\"]:\n",
    "        actor_counter +=1\n",
    "        hollywood_graph.add_node(actor, **diz, bipartite = 1)\n",
    "print(actor_counter)\n",
    "edge_counter = 0\n",
    "for edge1, edge2, diz in edges:\n",
    "    if edge1 in hollywood_graph.nodes() and edge2 in hollywood_graph.nodes():\n",
    "        edge_counter +=1\n",
    "        hollywood_graph.add_edge(edge1, edge2, **diz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "932bbbda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T22:17:18.884917Z",
     "start_time": "2026-02-08T22:17:16.211292Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "to_dump = nx.readwrite.json_graph.node_link_data(hollywood_graph)\n",
    "with open(\"hollywood_graph.json\", \"w\") as f:\n",
    "    json.dump(to_dump, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_mining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
